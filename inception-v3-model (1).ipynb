{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-02T12:21:38.189651Z","iopub.execute_input":"2023-09-02T12:21:38.190212Z","iopub.status.idle":"2023-09-02T12:21:38.542387Z","shell.execute_reply.started":"2023-09-02T12:21:38.190172Z","shell.execute_reply":"2023-09-02T12:21:38.541436Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Problem Statement\n\n<li>VegCart(Random Name) is a fresh produce supply chain company. They are pioneers in solving one of the toughest supply chain problems of the world by leveraging innovative technology. They source fresh produce from farmers and deliver them to businesses within 12 hours. An integral component of their automation process is the development of robust classifiers which can distinguish between images of different types of vegetables, while also correctly labeling images that do not contain any one type of vegetable as noise.</li>\n\n<li>As a starting point, we have been tasked with preparing a multiclass classifier for identifying these vegetables. The dataset provided has all the required images to achieve the task.</li>","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.metrics as metrics\n\n\n# Tensorflow import\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, ReLU, Softmax, BatchNormalization, Dropout\nfrom tensorflow.random import set_seed\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-02T12:21:47.360840Z","iopub.execute_input":"2023-09-02T12:21:47.361614Z","iopub.status.idle":"2023-09-02T12:21:56.766094Z","shell.execute_reply.started":"2023-09-02T12:21:47.361580Z","shell.execute_reply":"2023-09-02T12:21:56.765027Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"set_seed(111) # set random seed\n\n# To supress any warnings during the flow\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-02T12:21:56.768044Z","iopub.execute_input":"2023-09-02T12:21:56.768691Z","iopub.status.idle":"2023-09-02T12:21:56.775677Z","shell.execute_reply.started":"2023-09-02T12:21:56.768662Z","shell.execute_reply":"2023-09-02T12:21:56.772443Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"train\")\nos.mkdir(\"test\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:21:59.248392Z","iopub.execute_input":"2023-09-02T12:21:59.248799Z","iopub.status.idle":"2023-09-02T12:21:59.254473Z","shell.execute_reply.started":"2023-09-02T12:21:59.248766Z","shell.execute_reply":"2023-09-02T12:21:59.253413Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nfrom PIL import Image\n\ndef create_matrix_collage(image_paths, rows, cols, output_size):\n    collage = Image.new('RGB', output_size)\n    width_per_image = output_size[0] // cols\n    height_per_image = output_size[1] // rows\n\n    for i in range(rows):\n        for j in range(cols):\n            img_path = image_paths[i * cols + j]\n            img = Image.open(img_path)\n            img = img.resize((width_per_image, height_per_image), Image.ANTIALIAS)\n            collage.paste(img, (j * width_per_image, i * height_per_image))\n\n    return collage\n\n\n\ndef image_generator(num = 2000):\n    base_path = \"/kaggle/input/vegetable-image-dataset/Vegetable Images/train\"\n    veget = os.listdir(base_path)\n    veget.sort()\n    labels = []\n    for i in range(1, num+1):\n        image_paths = []  # Replace with your image paths\n        rows = 4  # Number of rows in the collage\n        cols = 4  # Number of columns in the collage\n        output_size = (128, 128)  # Size of the final collage image (rows * cols)\n        temp = [0]*15\n        for j in range(1, 17):\n            num = np.random.randint(0, 15)\n            veg_name = veget[num]\n            veg_path = os.path.join(base_path, veg_name)\n            img_num = np.random.randint(0, 1000)\n            lst = os.listdir(veg_path)\n            veg_img_path = os.path.join(veg_path, lst[img_num])\n            image_paths.append(veg_img_path)\n            temp[num] = 1\n        \n        collage = create_matrix_collage(image_paths, rows, cols, output_size)\n        collage.save(f\"train/img_{i}.jpg\")\n        labels.append(temp)\n    return veget, labels\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:22:00.270668Z","iopub.execute_input":"2023-09-02T12:22:00.271209Z","iopub.status.idle":"2023-09-02T12:22:00.287230Z","shell.execute_reply.started":"2023-09-02T12:22:00.271179Z","shell.execute_reply":"2023-09-02T12:22:00.286135Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"veget, labels = image_generator(2000)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:22:01.368777Z","iopub.execute_input":"2023-09-02T12:22:01.369147Z","iopub.status.idle":"2023-09-02T12:24:35.989346Z","shell.execute_reply.started":"2023-09-02T12:22:01.369116Z","shell.execute_reply":"2023-09-02T12:24:35.988291Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df = pd.DataFrame(labels, columns = veget)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:24:35.991527Z","iopub.execute_input":"2023-09-02T12:24:35.992236Z","iopub.status.idle":"2023-09-02T12:24:36.012181Z","shell.execute_reply.started":"2023-09-02T12:24:35.992202Z","shell.execute_reply":"2023-09-02T12:24:36.011030Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"labels_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:24:36.013508Z","iopub.execute_input":"2023-09-02T12:24:36.014361Z","iopub.status.idle":"2023-09-02T12:24:36.043642Z","shell.execute_reply.started":"2023-09-02T12:24:36.014328Z","shell.execute_reply":"2023-09-02T12:24:36.041903Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   Bean  Bitter_Gourd  Bottle_Gourd  Brinjal  Broccoli  Cabbage  Capsicum  \\\n0     1             0             1        1         0        1         1   \n1     1             0             1        1         0        1         1   \n2     1             1             1        1         0        0         1   \n3     1             1             0        1         0        1         1   \n4     1             1             1        0         0        1         0   \n\n   Carrot  Cauliflower  Cucumber  Papaya  Potato  Pumpkin  Radish  Tomato  \n0       1            1         0       0       1        1       1       0  \n1       0            1         1       1       0        0       1       1  \n2       1            1         1       0       0        1       1       1  \n3       1            0         1       0       1        1       1       1  \n4       1            1         1       0       1        1       1       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bean</th>\n      <th>Bitter_Gourd</th>\n      <th>Bottle_Gourd</th>\n      <th>Brinjal</th>\n      <th>Broccoli</th>\n      <th>Cabbage</th>\n      <th>Capsicum</th>\n      <th>Carrot</th>\n      <th>Cauliflower</th>\n      <th>Cucumber</th>\n      <th>Papaya</th>\n      <th>Potato</th>\n      <th>Pumpkin</th>\n      <th>Radish</th>\n      <th>Tomato</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"L = os.listdir(\"/kaggle/working/train\")\nL.sort()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:24:36.046837Z","iopub.execute_input":"2023-09-02T12:24:36.047813Z","iopub.status.idle":"2023-09-02T12:24:36.055013Z","shell.execute_reply.started":"2023-09-02T12:24:36.047779Z","shell.execute_reply":"2023-09-02T12:24:36.054017Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"veget","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:24:36.056391Z","iopub.execute_input":"2023-09-02T12:24:36.057068Z","iopub.status.idle":"2023-09-02T12:24:36.066493Z","shell.execute_reply.started":"2023-09-02T12:24:36.057034Z","shell.execute_reply":"2023-09-02T12:24:36.065256Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['Bean',\n 'Bitter_Gourd',\n 'Bottle_Gourd',\n 'Brinjal',\n 'Broccoli',\n 'Cabbage',\n 'Capsicum',\n 'Carrot',\n 'Cauliflower',\n 'Cucumber',\n 'Papaya',\n 'Potato',\n 'Pumpkin',\n 'Radish',\n 'Tomato']"},"metadata":{}}]},{"cell_type":"code","source":"newsize = (128, 128)\nbase_path = \"/kaggle/input/vegetable-image-dataset/Vegetable Images/validation\"\nnew_path = \"/kaggle/working/train\"\nimg_num = 2001\nadd_num = 133\nlabels = []\nfor id, name in enumerate(veget):\n    if id == 14:\n        add_num = 138\n    temp = [0]*15\n    temp[id] = 1\n    veg_name_path = os.path.join(base_path, name)\n    lst = os.listdir(veg_name_path)\n    for i in range(add_num):\n        num = np.random.randint(0, len(lst))\n        veg_img_path = os.path.join(veg_name_path, lst[num])\n        img = Image.open(veg_img_path)\n        img = img.resize(newsize)\n        img_name = f\"img_{img_num}\" + \".jpg\"\n        new_train_path = os.path.join(new_path, img_name)\n        img.save(new_train_path)\n        labels.append(temp)\n        img_num += 1\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:25:08.016207Z","iopub.execute_input":"2023-09-02T12:25:08.016568Z","iopub.status.idle":"2023-09-02T12:25:19.859115Z","shell.execute_reply.started":"2023-09-02T12:25:08.016541Z","shell.execute_reply":"2023-09-02T12:25:19.858107Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"temp_df = pd.DataFrame(labels, columns = veget)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:25:19.861083Z","iopub.execute_input":"2023-09-02T12:25:19.861792Z","iopub.status.idle":"2023-09-02T12:25:19.886210Z","shell.execute_reply.started":"2023-09-02T12:25:19.861758Z","shell.execute_reply":"2023-09-02T12:25:19.885319Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df = pd.concat([labels_df, temp_df])","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:25:26.527653Z","iopub.execute_input":"2023-09-02T12:25:26.528040Z","iopub.status.idle":"2023-09-02T12:25:26.535056Z","shell.execute_reply.started":"2023-09-02T12:25:26.528006Z","shell.execute_reply":"2023-09-02T12:25:26.534151Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"labels_df.reset_index(drop = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:25:28.242767Z","iopub.execute_input":"2023-09-02T12:25:28.243166Z","iopub.status.idle":"2023-09-02T12:25:28.250737Z","shell.execute_reply.started":"2023-09-02T12:25:28.243134Z","shell.execute_reply":"2023-09-02T12:25:28.249496Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"labels_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:25:43.296184Z","iopub.execute_input":"2023-09-02T12:25:43.296769Z","iopub.status.idle":"2023-09-02T12:25:43.322834Z","shell.execute_reply.started":"2023-09-02T12:25:43.296729Z","shell.execute_reply":"2023-09-02T12:25:43.321748Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   Bean  Bitter_Gourd  Bottle_Gourd  Brinjal  Broccoli  Cabbage  Capsicum  \\\n0     1             0             1        1         0        1         1   \n1     1             0             1        1         0        1         1   \n2     1             1             1        1         0        0         1   \n3     1             1             0        1         0        1         1   \n4     1             1             1        0         0        1         0   \n\n   Carrot  Cauliflower  Cucumber  Papaya  Potato  Pumpkin  Radish  Tomato  \n0       1            1         0       0       1        1       1       0  \n1       0            1         1       1       0        0       1       1  \n2       1            1         1       0       0        1       1       1  \n3       1            0         1       0       1        1       1       1  \n4       1            1         1       0       1        1       1       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bean</th>\n      <th>Bitter_Gourd</th>\n      <th>Bottle_Gourd</th>\n      <th>Brinjal</th>\n      <th>Broccoli</th>\n      <th>Cabbage</th>\n      <th>Capsicum</th>\n      <th>Carrot</th>\n      <th>Cauliflower</th>\n      <th>Cucumber</th>\n      <th>Papaya</th>\n      <th>Potato</th>\n      <th>Pumpkin</th>\n      <th>Radish</th>\n      <th>Tomato</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# !zip -r file.zip /kaggle/working/train\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:26:04.999075Z","iopub.execute_input":"2023-09-02T12:26:05.000002Z","iopub.status.idle":"2023-09-02T12:26:05.004380Z","shell.execute_reply.started":"2023-09-02T12:26:04.999949Z","shell.execute_reply":"2023-09-02T12:26:05.003330Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Import the inception v3 model\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:26:05.829966Z","iopub.execute_input":"2023-09-02T12:26:05.830690Z","iopub.status.idle":"2023-09-02T12:26:05.835160Z","shell.execute_reply.started":"2023-09-02T12:26:05.830656Z","shell.execute_reply":"2023-09-02T12:26:05.834040Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# def inception_v3(inputs,\n#                  num_classes=15,\n#                  is_training=True,\n#                  dropout_keep_prob=0.8,\n#                  min_depth=16,\n#                  depth_multiplier=1.0,\n#                  prediction_fn=tf.sigmoid,\n#                  spatial_squeeze=True,\n#                  reuse=None,\n#                  scope='InceptionV3'):","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:26:06.194739Z","iopub.execute_input":"2023-09-02T12:26:06.195122Z","iopub.status.idle":"2023-09-02T12:26:06.200445Z","shell.execute_reply.started":"2023-09-02T12:26:06.195092Z","shell.execute_reply":"2023-09-02T12:26:06.199421Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# import the inception v3 model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:26:07.330338Z","iopub.execute_input":"2023-09-02T12:26:07.331061Z","iopub.status.idle":"2023-09-02T12:26:07.337109Z","shell.execute_reply.started":"2023-09-02T12:26:07.331026Z","shell.execute_reply":"2023-09-02T12:26:07.336022Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"pre_trained_model = InceptionV3(input_shape = (128, 128, 3),\n                                include_top = False,\n                               weights = 'imagenet')","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:26:08.489015Z","iopub.execute_input":"2023-09-02T12:26:08.489383Z","iopub.status.idle":"2023-09-02T12:26:14.958217Z","shell.execute_reply.started":"2023-09-02T12:26:08.489355Z","shell.execute_reply":"2023-09-02T12:26:14.957217Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in pre_trained_model.layers:\n    layers.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:27:05.411433Z","iopub.execute_input":"2023-09-02T12:27:05.411791Z","iopub.status.idle":"2023-09-02T12:27:05.417020Z","shell.execute_reply.started":"2023-09-02T12:27:05.411762Z","shell.execute_reply":"2023-09-02T12:27:05.415929Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:27:07.793406Z","iopub.execute_input":"2023-09-02T12:27:07.793771Z","iopub.status.idle":"2023-09-02T12:27:07.798210Z","shell.execute_reply.started":"2023-09-02T12:27:07.793738Z","shell.execute_reply":"2023-09-02T12:27:07.797051Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\nfrom sklearn.metrics import f1_score\n\ndef model_creator(pre_trained_model):\n    # flatten the output layer to one dimension\n    x = layers.Flatten()(pre_trained_model.output)\n    # add a fully layer with 1024 hidden units and ReLU activation\n    x = layers.Dense(1024, activation = 'relu')(x)\n    # add a dropout rate of 0.2\n    x = layers.Dropout(0.2)(x)\n    # add a final sigmoid layer for classfication\n    x = layers.Dense(15, activation = \"sigmoid\")(x)\n    model = Model(pre_trained_model.input, x)\n    model.compile(optimizer = RMSprop(lr = 0.0001),\n                 loss = \"binary_crossentropy\", \n                 metrics = ['accuracy'])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:27:16.071548Z","iopub.execute_input":"2023-09-02T12:27:16.071932Z","iopub.status.idle":"2023-09-02T12:27:16.080613Z","shell.execute_reply.started":"2023-09-02T12:27:16.071901Z","shell.execute_reply":"2023-09-02T12:27:16.079298Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:27:19.323130Z","iopub.execute_input":"2023-09-02T12:27:19.323797Z","iopub.status.idle":"2023-09-02T12:27:19.329056Z","shell.execute_reply.started":"2023-09-02T12:27:19.323766Z","shell.execute_reply":"2023-09-02T12:27:19.328028Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Preprocessing step","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:27:20.429517Z","iopub.execute_input":"2023-09-02T12:27:20.429884Z","iopub.status.idle":"2023-09-02T12:27:20.434001Z","shell.execute_reply.started":"2023-09-02T12:27:20.429854Z","shell.execute_reply":"2023-09-02T12:27:20.433095Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from keras import layers\nimport tensorflow as tf\ndata_augmentation = tf.keras.Sequential([\n  layers.Rescaling(1./255)\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:27:20.916074Z","iopub.execute_input":"2023-09-02T12:27:20.916454Z","iopub.status.idle":"2023-09-02T12:27:20.926549Z","shell.execute_reply.started":"2023-09-02T12:27:20.916425Z","shell.execute_reply":"2023-09-02T12:27:20.925401Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import StratifiedKFold\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:27:23.256546Z","iopub.execute_input":"2023-09-02T12:27:23.257434Z","iopub.status.idle":"2023-09-02T12:27:23.274411Z","shell.execute_reply.started":"2023-09-02T12:27:23.257393Z","shell.execute_reply":"2023-09-02T12:27:23.273461Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []; y = []\nfor img in os.listdir(\"/kaggle/working/train\"):\n    img_path = \"/kaggle/working/train\" + \"/\" + img\n    label = int(img.split(\"_\")[1].split(\".\")[0])-1\n    label = list(labels_df.iloc[label, :].values)\n    img = Image.open(img_path)\n    arr = np.asarray(img)\n    arr = data_augmentation(arr)\n    X.append(arr)\n    y.append(label)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:27:25.823125Z","iopub.execute_input":"2023-09-02T12:27:25.823492Z","iopub.status.idle":"2023-09-02T12:27:32.864564Z","shell.execute_reply.started":"2023-09-02T12:27:25.823463Z","shell.execute_reply":"2023-09-02T12:27:32.863481Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:28:00.973840Z","iopub.execute_input":"2023-09-02T12:28:00.974204Z","iopub.status.idle":"2023-09-02T12:28:02.218183Z","shell.execute_reply.started":"2023-09-02T12:28:00.974176Z","shell.execute_reply":"2023-09-02T12:28:02.217091Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\n\n# Define the number of folds\nk = 10  # You can adjust this as needed\n\n# Initialize KFold\nkf = KFold(n_splits=k, shuffle=True, random_state=42)\n\n# Lists to store training histories\nall_histories = []\nmodel = model_creator(pre_trained_model)\n# Loop through the folds\nfor train_index, val_index in kf.split(X):\n    X_train, X_val = X[train_index], X[val_index]\n    y_train, y_val = y[train_index], y[val_index]\n\n    # Create and compile your Keras model\n#     model = model_creator(pre_trained_model)\n\n    # Train the model\n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_val, y_val),\n        batch_size=50,\n        epochs=100,\n        verbose=2  # You can adjust verbosity\n    )\n\n    # Append the training history to the list\n    all_histories.append(history)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T12:28:50.861348Z","iopub.execute_input":"2023-09-02T12:28:50.861704Z","iopub.status.idle":"2023-09-02T14:17:42.078674Z","shell.execute_reply.started":"2023-09-02T12:28:50.861674Z","shell.execute_reply":"2023-09-02T14:17:42.077252Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/100\n72/72 - 47s - loss: 0.5313 - accuracy: 0.0894 - val_loss: 1.5330 - val_accuracy: 0.0350 - 47s/epoch - 658ms/step\nEpoch 2/100\n72/72 - 6s - loss: 0.4515 - accuracy: 0.0933 - val_loss: 1.6550 - val_accuracy: 0.0350 - 6s/epoch - 86ms/step\nEpoch 3/100\n72/72 - 6s - loss: 0.4212 - accuracy: 0.1525 - val_loss: 2.0265 - val_accuracy: 0.0800 - 6s/epoch - 85ms/step\nEpoch 4/100\n72/72 - 6s - loss: 0.4204 - accuracy: 0.1847 - val_loss: 0.4282 - val_accuracy: 0.1875 - 6s/epoch - 86ms/step\nEpoch 5/100\n72/72 - 6s - loss: 0.4061 - accuracy: 0.2528 - val_loss: 5.4567 - val_accuracy: 0.1575 - 6s/epoch - 86ms/step\nEpoch 6/100\n72/72 - 6s - loss: 0.3961 - accuracy: 0.2617 - val_loss: 9.9689 - val_accuracy: 0.3225 - 6s/epoch - 86ms/step\nEpoch 7/100\n72/72 - 6s - loss: 0.3733 - accuracy: 0.3278 - val_loss: 0.4612 - val_accuracy: 0.2550 - 6s/epoch - 85ms/step\nEpoch 8/100\n72/72 - 6s - loss: 0.3588 - accuracy: 0.4072 - val_loss: 0.3677 - val_accuracy: 0.3400 - 6s/epoch - 86ms/step\nEpoch 9/100\n72/72 - 6s - loss: 0.3484 - accuracy: 0.4311 - val_loss: 0.3608 - val_accuracy: 0.4000 - 6s/epoch - 86ms/step\nEpoch 10/100\n72/72 - 6s - loss: 0.3394 - accuracy: 0.4847 - val_loss: 0.3498 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 11/100\n72/72 - 6s - loss: 0.3309 - accuracy: 0.5167 - val_loss: 0.7241 - val_accuracy: 0.3525 - 6s/epoch - 85ms/step\nEpoch 12/100\n72/72 - 6s - loss: 0.3248 - accuracy: 0.4861 - val_loss: 0.4332 - val_accuracy: 0.3800 - 6s/epoch - 86ms/step\nEpoch 13/100\n72/72 - 6s - loss: 0.3103 - accuracy: 0.4914 - val_loss: 0.3647 - val_accuracy: 0.3975 - 6s/epoch - 85ms/step\nEpoch 14/100\n72/72 - 6s - loss: 0.3019 - accuracy: 0.4900 - val_loss: 0.3406 - val_accuracy: 0.4450 - 6s/epoch - 85ms/step\nEpoch 15/100\n72/72 - 6s - loss: 0.2945 - accuracy: 0.4900 - val_loss: 0.4226 - val_accuracy: 0.3850 - 6s/epoch - 85ms/step\nEpoch 16/100\n72/72 - 6s - loss: 0.2833 - accuracy: 0.5006 - val_loss: 0.3529 - val_accuracy: 0.4150 - 6s/epoch - 86ms/step\nEpoch 17/100\n72/72 - 6s - loss: 0.2780 - accuracy: 0.4847 - val_loss: 0.3684 - val_accuracy: 0.4600 - 6s/epoch - 86ms/step\nEpoch 18/100\n72/72 - 6s - loss: 0.2612 - accuracy: 0.4969 - val_loss: 0.3357 - val_accuracy: 0.4650 - 6s/epoch - 87ms/step\nEpoch 19/100\n72/72 - 6s - loss: 0.2545 - accuracy: 0.4836 - val_loss: 0.3616 - val_accuracy: 0.4225 - 6s/epoch - 86ms/step\nEpoch 20/100\n72/72 - 6s - loss: 0.2357 - accuracy: 0.4969 - val_loss: 0.3788 - val_accuracy: 0.4400 - 6s/epoch - 88ms/step\nEpoch 21/100\n72/72 - 6s - loss: 0.2216 - accuracy: 0.4964 - val_loss: 0.3418 - val_accuracy: 0.4750 - 6s/epoch - 86ms/step\nEpoch 22/100\n72/72 - 6s - loss: 0.2086 - accuracy: 0.4958 - val_loss: 0.3442 - val_accuracy: 0.4725 - 6s/epoch - 87ms/step\nEpoch 23/100\n72/72 - 6s - loss: 0.1876 - accuracy: 0.4989 - val_loss: 0.3613 - val_accuracy: 0.4700 - 6s/epoch - 86ms/step\nEpoch 24/100\n72/72 - 6s - loss: 0.1694 - accuracy: 0.4972 - val_loss: 0.4304 - val_accuracy: 0.4275 - 6s/epoch - 86ms/step\nEpoch 25/100\n72/72 - 6s - loss: 0.1447 - accuracy: 0.4986 - val_loss: 0.4157 - val_accuracy: 0.4650 - 6s/epoch - 87ms/step\nEpoch 26/100\n72/72 - 6s - loss: 0.1263 - accuracy: 0.5033 - val_loss: 0.5797 - val_accuracy: 0.4825 - 6s/epoch - 86ms/step\nEpoch 27/100\n72/72 - 6s - loss: 0.1079 - accuracy: 0.5056 - val_loss: 0.5154 - val_accuracy: 0.4675 - 6s/epoch - 86ms/step\nEpoch 28/100\n72/72 - 6s - loss: 0.0974 - accuracy: 0.5053 - val_loss: 0.5771 - val_accuracy: 0.4800 - 6s/epoch - 87ms/step\nEpoch 29/100\n72/72 - 6s - loss: 0.0812 - accuracy: 0.5083 - val_loss: 0.6764 - val_accuracy: 0.4400 - 6s/epoch - 86ms/step\nEpoch 30/100\n72/72 - 6s - loss: 0.0706 - accuracy: 0.5108 - val_loss: 0.7420 - val_accuracy: 0.4675 - 6s/epoch - 87ms/step\nEpoch 31/100\n72/72 - 6s - loss: 0.0692 - accuracy: 0.5094 - val_loss: 0.6092 - val_accuracy: 0.4550 - 6s/epoch - 87ms/step\nEpoch 32/100\n72/72 - 6s - loss: 0.0615 - accuracy: 0.5142 - val_loss: 0.7318 - val_accuracy: 0.4675 - 6s/epoch - 87ms/step\nEpoch 33/100\n72/72 - 6s - loss: 0.0497 - accuracy: 0.5136 - val_loss: 0.7920 - val_accuracy: 0.4750 - 6s/epoch - 87ms/step\nEpoch 34/100\n72/72 - 6s - loss: 0.0462 - accuracy: 0.5164 - val_loss: 0.6427 - val_accuracy: 0.4675 - 6s/epoch - 87ms/step\nEpoch 35/100\n72/72 - 6s - loss: 0.0401 - accuracy: 0.5161 - val_loss: 0.7632 - val_accuracy: 0.4625 - 6s/epoch - 87ms/step\nEpoch 36/100\n72/72 - 6s - loss: 0.0361 - accuracy: 0.5150 - val_loss: 0.6951 - val_accuracy: 0.4850 - 6s/epoch - 87ms/step\nEpoch 37/100\n72/72 - 6s - loss: 0.0350 - accuracy: 0.5181 - val_loss: 0.8622 - val_accuracy: 0.4675 - 6s/epoch - 87ms/step\nEpoch 38/100\n72/72 - 6s - loss: 0.0334 - accuracy: 0.5211 - val_loss: 0.7226 - val_accuracy: 0.4975 - 6s/epoch - 86ms/step\nEpoch 39/100\n72/72 - 6s - loss: 0.0305 - accuracy: 0.5222 - val_loss: 1.0575 - val_accuracy: 0.3425 - 6s/epoch - 86ms/step\nEpoch 40/100\n72/72 - 6s - loss: 0.0278 - accuracy: 0.5233 - val_loss: 0.7148 - val_accuracy: 0.5025 - 6s/epoch - 88ms/step\nEpoch 41/100\n72/72 - 6s - loss: 0.0227 - accuracy: 0.5303 - val_loss: 0.7711 - val_accuracy: 0.5100 - 6s/epoch - 88ms/step\nEpoch 42/100\n72/72 - 6s - loss: 0.0251 - accuracy: 0.5297 - val_loss: 0.9373 - val_accuracy: 0.4825 - 6s/epoch - 87ms/step\nEpoch 43/100\n72/72 - 6s - loss: 0.0231 - accuracy: 0.5381 - val_loss: 0.6858 - val_accuracy: 0.4500 - 6s/epoch - 86ms/step\nEpoch 44/100\n72/72 - 6s - loss: 0.0198 - accuracy: 0.5350 - val_loss: 0.6815 - val_accuracy: 0.4975 - 6s/epoch - 86ms/step\nEpoch 45/100\n72/72 - 6s - loss: 0.0200 - accuracy: 0.5294 - val_loss: 0.7296 - val_accuracy: 0.4700 - 6s/epoch - 86ms/step\nEpoch 46/100\n72/72 - 6s - loss: 0.0159 - accuracy: 0.5275 - val_loss: 0.7999 - val_accuracy: 0.4575 - 6s/epoch - 87ms/step\nEpoch 47/100\n72/72 - 6s - loss: 0.0209 - accuracy: 0.5242 - val_loss: 0.8066 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 48/100\n72/72 - 6s - loss: 0.0188 - accuracy: 0.5308 - val_loss: 0.7527 - val_accuracy: 0.5250 - 6s/epoch - 86ms/step\nEpoch 49/100\n72/72 - 6s - loss: 0.0208 - accuracy: 0.5367 - val_loss: 0.7703 - val_accuracy: 0.5000 - 6s/epoch - 87ms/step\nEpoch 50/100\n72/72 - 6s - loss: 0.0166 - accuracy: 0.5361 - val_loss: 0.7349 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 51/100\n72/72 - 6s - loss: 0.0146 - accuracy: 0.5444 - val_loss: 0.8536 - val_accuracy: 0.4725 - 6s/epoch - 88ms/step\nEpoch 52/100\n72/72 - 6s - loss: 0.0120 - accuracy: 0.5494 - val_loss: 0.7294 - val_accuracy: 0.5025 - 6s/epoch - 86ms/step\nEpoch 53/100\n72/72 - 6s - loss: 0.0122 - accuracy: 0.5419 - val_loss: 0.8168 - val_accuracy: 0.4625 - 6s/epoch - 86ms/step\nEpoch 54/100\n72/72 - 6s - loss: 0.0151 - accuracy: 0.5406 - val_loss: 1.0519 - val_accuracy: 0.4750 - 6s/epoch - 86ms/step\nEpoch 55/100\n72/72 - 6s - loss: 0.0103 - accuracy: 0.5392 - val_loss: 0.7874 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 56/100\n72/72 - 6s - loss: 0.0138 - accuracy: 0.5356 - val_loss: 0.7976 - val_accuracy: 0.4900 - 6s/epoch - 87ms/step\nEpoch 57/100\n72/72 - 6s - loss: 0.0119 - accuracy: 0.5339 - val_loss: 0.6671 - val_accuracy: 0.4750 - 6s/epoch - 87ms/step\nEpoch 58/100\n72/72 - 6s - loss: 0.0112 - accuracy: 0.5392 - val_loss: 0.8359 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 59/100\n72/72 - 6s - loss: 0.0085 - accuracy: 0.5472 - val_loss: 0.9522 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 60/100\n72/72 - 6s - loss: 0.0135 - accuracy: 0.5317 - val_loss: 0.8028 - val_accuracy: 0.4925 - 6s/epoch - 86ms/step\nEpoch 61/100\n72/72 - 6s - loss: 0.0124 - accuracy: 0.5372 - val_loss: 1.0850 - val_accuracy: 0.3925 - 6s/epoch - 88ms/step\nEpoch 62/100\n72/72 - 6s - loss: 0.0108 - accuracy: 0.5461 - val_loss: 1.0257 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 63/100\n72/72 - 6s - loss: 0.0110 - accuracy: 0.5458 - val_loss: 0.8963 - val_accuracy: 0.4900 - 6s/epoch - 87ms/step\nEpoch 64/100\n72/72 - 6s - loss: 0.0103 - accuracy: 0.5400 - val_loss: 0.9086 - val_accuracy: 0.4500 - 6s/epoch - 87ms/step\nEpoch 65/100\n72/72 - 6s - loss: 0.0074 - accuracy: 0.5433 - val_loss: 0.7684 - val_accuracy: 0.5050 - 6s/epoch - 87ms/step\nEpoch 66/100\n72/72 - 6s - loss: 0.0067 - accuracy: 0.5419 - val_loss: 0.7950 - val_accuracy: 0.4900 - 6s/epoch - 87ms/step\nEpoch 67/100\n72/72 - 6s - loss: 0.0071 - accuracy: 0.5461 - val_loss: 0.7785 - val_accuracy: 0.5825 - 6s/epoch - 87ms/step\nEpoch 68/100\n72/72 - 6s - loss: 0.0065 - accuracy: 0.5567 - val_loss: 0.9048 - val_accuracy: 0.4300 - 6s/epoch - 87ms/step\nEpoch 69/100\n72/72 - 6s - loss: 0.0054 - accuracy: 0.5536 - val_loss: 0.7456 - val_accuracy: 0.5000 - 6s/epoch - 88ms/step\nEpoch 70/100\n72/72 - 6s - loss: 0.0070 - accuracy: 0.5542 - val_loss: 0.8890 - val_accuracy: 0.4675 - 6s/epoch - 86ms/step\nEpoch 71/100\n72/72 - 6s - loss: 0.0071 - accuracy: 0.5558 - val_loss: 0.7892 - val_accuracy: 0.4800 - 6s/epoch - 87ms/step\nEpoch 72/100\n72/72 - 6s - loss: 0.0063 - accuracy: 0.5422 - val_loss: 0.7625 - val_accuracy: 0.4975 - 6s/epoch - 86ms/step\nEpoch 73/100\n72/72 - 6s - loss: 0.0073 - accuracy: 0.5400 - val_loss: 0.7365 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 74/100\n72/72 - 6s - loss: 0.0063 - accuracy: 0.5567 - val_loss: 0.7354 - val_accuracy: 0.4700 - 6s/epoch - 86ms/step\nEpoch 75/100\n72/72 - 6s - loss: 0.0063 - accuracy: 0.5456 - val_loss: 0.8249 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 76/100\n72/72 - 6s - loss: 0.0064 - accuracy: 0.5483 - val_loss: 0.7913 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 77/100\n72/72 - 6s - loss: 0.0048 - accuracy: 0.5558 - val_loss: 0.8260 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 78/100\n72/72 - 6s - loss: 0.0051 - accuracy: 0.5528 - val_loss: 0.7895 - val_accuracy: 0.5050 - 6s/epoch - 86ms/step\nEpoch 79/100\n72/72 - 6s - loss: 0.0081 - accuracy: 0.5461 - val_loss: 0.8505 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 80/100\n72/72 - 6s - loss: 0.0063 - accuracy: 0.5603 - val_loss: 0.8450 - val_accuracy: 0.4950 - 6s/epoch - 86ms/step\nEpoch 81/100\n72/72 - 6s - loss: 0.0054 - accuracy: 0.5594 - val_loss: 0.8669 - val_accuracy: 0.4900 - 6s/epoch - 88ms/step\nEpoch 82/100\n72/72 - 6s - loss: 0.0056 - accuracy: 0.5594 - val_loss: 0.8536 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 83/100\n72/72 - 6s - loss: 0.0043 - accuracy: 0.5494 - val_loss: 0.8003 - val_accuracy: 0.5075 - 6s/epoch - 86ms/step\nEpoch 84/100\n72/72 - 6s - loss: 0.0039 - accuracy: 0.5625 - val_loss: 0.7568 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 85/100\n72/72 - 6s - loss: 0.0074 - accuracy: 0.5631 - val_loss: 0.8013 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 86/100\n72/72 - 6s - loss: 0.0063 - accuracy: 0.5514 - val_loss: 0.7263 - val_accuracy: 0.5050 - 6s/epoch - 88ms/step\nEpoch 87/100\n72/72 - 6s - loss: 0.0069 - accuracy: 0.5603 - val_loss: 0.8738 - val_accuracy: 0.5300 - 6s/epoch - 86ms/step\nEpoch 88/100\n72/72 - 6s - loss: 0.0035 - accuracy: 0.5625 - val_loss: 0.8578 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 89/100\n72/72 - 6s - loss: 0.0031 - accuracy: 0.5631 - val_loss: 0.8693 - val_accuracy: 0.5350 - 6s/epoch - 86ms/step\nEpoch 90/100\n72/72 - 6s - loss: 0.0024 - accuracy: 0.5589 - val_loss: 0.7753 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 91/100\n72/72 - 6s - loss: 0.0024 - accuracy: 0.5633 - val_loss: 0.8401 - val_accuracy: 0.5300 - 6s/epoch - 88ms/step\nEpoch 92/100\n72/72 - 6s - loss: 0.0029 - accuracy: 0.5531 - val_loss: 1.0549 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 93/100\n72/72 - 6s - loss: 0.0029 - accuracy: 0.5600 - val_loss: 0.7645 - val_accuracy: 0.4900 - 6s/epoch - 86ms/step\nEpoch 94/100\n72/72 - 6s - loss: 0.0027 - accuracy: 0.5664 - val_loss: 0.8236 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 95/100\n72/72 - 6s - loss: 0.0033 - accuracy: 0.5681 - val_loss: 0.9350 - val_accuracy: 0.4750 - 6s/epoch - 86ms/step\nEpoch 96/100\n72/72 - 6s - loss: 0.0018 - accuracy: 0.5617 - val_loss: 0.8341 - val_accuracy: 0.5025 - 6s/epoch - 87ms/step\nEpoch 97/100\n72/72 - 6s - loss: 0.0024 - accuracy: 0.5636 - val_loss: 0.9248 - val_accuracy: 0.4825 - 6s/epoch - 86ms/step\nEpoch 98/100\n72/72 - 6s - loss: 0.0019 - accuracy: 0.5625 - val_loss: 0.8709 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 99/100\n72/72 - 6s - loss: 0.0027 - accuracy: 0.5639 - val_loss: 0.9334 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 100/100\n72/72 - 6s - loss: 0.0030 - accuracy: 0.5611 - val_loss: 0.7959 - val_accuracy: 0.4900 - 6s/epoch - 86ms/step\nEpoch 1/100\n72/72 - 6s - loss: 0.0659 - accuracy: 0.5364 - val_loss: 0.0285 - val_accuracy: 0.5400 - 6s/epoch - 88ms/step\nEpoch 2/100\n72/72 - 6s - loss: 0.0278 - accuracy: 0.5353 - val_loss: 0.0105 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 3/100\n72/72 - 6s - loss: 0.0138 - accuracy: 0.5386 - val_loss: 0.0748 - val_accuracy: 0.5000 - 6s/epoch - 86ms/step\nEpoch 4/100\n72/72 - 6s - loss: 0.0087 - accuracy: 0.5403 - val_loss: 0.0187 - val_accuracy: 0.5725 - 6s/epoch - 87ms/step\nEpoch 5/100\n72/72 - 6s - loss: 0.0078 - accuracy: 0.5528 - val_loss: 0.0102 - val_accuracy: 0.5250 - 6s/epoch - 86ms/step\nEpoch 6/100\n72/72 - 6s - loss: 0.0075 - accuracy: 0.5503 - val_loss: 0.0501 - val_accuracy: 0.5150 - 6s/epoch - 87ms/step\nEpoch 7/100\n72/72 - 6s - loss: 0.0056 - accuracy: 0.5386 - val_loss: 0.0089 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 8/100\n72/72 - 6s - loss: 0.0050 - accuracy: 0.5481 - val_loss: 0.0072 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 9/100\n72/72 - 6s - loss: 0.0041 - accuracy: 0.5533 - val_loss: 0.0102 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 10/100\n72/72 - 6s - loss: 0.0051 - accuracy: 0.5478 - val_loss: 0.0290 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 11/100\n72/72 - 6s - loss: 0.0054 - accuracy: 0.5447 - val_loss: 0.0142 - val_accuracy: 0.6175 - 6s/epoch - 89ms/step\nEpoch 12/100\n72/72 - 6s - loss: 0.0051 - accuracy: 0.5483 - val_loss: 0.0408 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 13/100\n72/72 - 6s - loss: 0.0051 - accuracy: 0.5503 - val_loss: 0.0252 - val_accuracy: 0.5875 - 6s/epoch - 87ms/step\nEpoch 14/100\n72/72 - 6s - loss: 0.0056 - accuracy: 0.5603 - val_loss: 0.0778 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 15/100\n72/72 - 6s - loss: 0.0059 - accuracy: 0.5517 - val_loss: 0.0926 - val_accuracy: 0.5225 - 6s/epoch - 87ms/step\nEpoch 16/100\n72/72 - 6s - loss: 0.0061 - accuracy: 0.5494 - val_loss: 0.0488 - val_accuracy: 0.5750 - 6s/epoch - 87ms/step\nEpoch 17/100\n72/72 - 6s - loss: 0.0045 - accuracy: 0.5528 - val_loss: 0.0095 - val_accuracy: 0.5825 - 6s/epoch - 86ms/step\nEpoch 18/100\n72/72 - 6s - loss: 0.0026 - accuracy: 0.5597 - val_loss: 0.0121 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 19/100\n72/72 - 6s - loss: 0.0028 - accuracy: 0.5489 - val_loss: 0.0154 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 20/100\n72/72 - 6s - loss: 0.0028 - accuracy: 0.5578 - val_loss: 0.0145 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 21/100\n72/72 - 6s - loss: 0.0019 - accuracy: 0.5489 - val_loss: 0.0134 - val_accuracy: 0.5300 - 6s/epoch - 88ms/step\nEpoch 22/100\n72/72 - 6s - loss: 0.0024 - accuracy: 0.5450 - val_loss: 0.0202 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 23/100\n72/72 - 6s - loss: 0.0028 - accuracy: 0.5531 - val_loss: 0.0088 - val_accuracy: 0.5350 - 6s/epoch - 86ms/step\nEpoch 24/100\n72/72 - 6s - loss: 0.0026 - accuracy: 0.5592 - val_loss: 0.0149 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 25/100\n72/72 - 6s - loss: 0.0028 - accuracy: 0.5561 - val_loss: 0.0518 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 26/100\n72/72 - 6s - loss: 0.0033 - accuracy: 0.5475 - val_loss: 0.0206 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 27/100\n72/72 - 6s - loss: 0.0044 - accuracy: 0.5544 - val_loss: 0.0306 - val_accuracy: 0.5125 - 6s/epoch - 88ms/step\nEpoch 28/100\n72/72 - 6s - loss: 0.0046 - accuracy: 0.5625 - val_loss: 0.0754 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 29/100\n72/72 - 6s - loss: 0.0050 - accuracy: 0.5694 - val_loss: 0.0204 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 30/100\n72/72 - 6s - loss: 0.0039 - accuracy: 0.5592 - val_loss: 0.0314 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 31/100\n72/72 - 6s - loss: 0.0031 - accuracy: 0.5628 - val_loss: 0.0357 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 32/100\n72/72 - 6s - loss: 0.0030 - accuracy: 0.5575 - val_loss: 0.0301 - val_accuracy: 0.6275 - 6s/epoch - 88ms/step\nEpoch 33/100\n72/72 - 6s - loss: 0.0024 - accuracy: 0.5622 - val_loss: 0.0657 - val_accuracy: 0.5100 - 6s/epoch - 86ms/step\nEpoch 34/100\n72/72 - 6s - loss: 0.0023 - accuracy: 0.5622 - val_loss: 0.0203 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 35/100\n72/72 - 6s - loss: 0.0021 - accuracy: 0.5600 - val_loss: 0.0230 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 36/100\n72/72 - 6s - loss: 0.0016 - accuracy: 0.5642 - val_loss: 0.0168 - val_accuracy: 0.5975 - 6s/epoch - 86ms/step\nEpoch 37/100\n72/72 - 6s - loss: 0.0015 - accuracy: 0.5650 - val_loss: 0.0157 - val_accuracy: 0.6150 - 6s/epoch - 88ms/step\nEpoch 38/100\n72/72 - 6s - loss: 0.0019 - accuracy: 0.5597 - val_loss: 0.0124 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 39/100\n72/72 - 6s - loss: 0.0023 - accuracy: 0.5625 - val_loss: 0.0337 - val_accuracy: 0.5350 - 6s/epoch - 86ms/step\nEpoch 40/100\n72/72 - 6s - loss: 0.0028 - accuracy: 0.5544 - val_loss: 0.0717 - val_accuracy: 0.5225 - 6s/epoch - 87ms/step\nEpoch 41/100\n72/72 - 6s - loss: 0.0016 - accuracy: 0.5547 - val_loss: 0.0189 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 42/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5508 - val_loss: 0.0364 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 43/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5469 - val_loss: 0.0107 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 44/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5572 - val_loss: 0.0483 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 45/100\n72/72 - 6s - loss: 0.0018 - accuracy: 0.5622 - val_loss: 0.0476 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 46/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5550 - val_loss: 0.0190 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 47/100\n72/72 - 6s - loss: 0.0021 - accuracy: 0.5564 - val_loss: 0.0456 - val_accuracy: 0.5375 - 6s/epoch - 88ms/step\nEpoch 48/100\n72/72 - 6s - loss: 0.0019 - accuracy: 0.5525 - val_loss: 0.0167 - val_accuracy: 0.5250 - 6s/epoch - 86ms/step\nEpoch 49/100\n72/72 - 6s - loss: 0.0021 - accuracy: 0.5439 - val_loss: 0.0187 - val_accuracy: 0.5750 - 6s/epoch - 86ms/step\nEpoch 50/100\n72/72 - 6s - loss: 0.0034 - accuracy: 0.5442 - val_loss: 0.0273 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 51/100\n72/72 - 6s - loss: 0.0028 - accuracy: 0.5422 - val_loss: 0.0265 - val_accuracy: 0.5175 - 6s/epoch - 86ms/step\nEpoch 52/100\n72/72 - 6s - loss: 0.0025 - accuracy: 0.5458 - val_loss: 0.0246 - val_accuracy: 0.5700 - 6s/epoch - 88ms/step\nEpoch 53/100\n72/72 - 6s - loss: 0.0034 - accuracy: 0.5544 - val_loss: 0.0492 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 54/100\n72/72 - 6s - loss: 0.0025 - accuracy: 0.5561 - val_loss: 0.0269 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 55/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5589 - val_loss: 0.0236 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 56/100\n72/72 - 6s - loss: 0.0023 - accuracy: 0.5494 - val_loss: 0.0297 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 57/100\n72/72 - 6s - loss: 0.0027 - accuracy: 0.5544 - val_loss: 0.0309 - val_accuracy: 0.5500 - 6s/epoch - 88ms/step\nEpoch 58/100\n72/72 - 6s - loss: 0.0023 - accuracy: 0.5542 - val_loss: 0.0189 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 59/100\n72/72 - 6s - loss: 0.0016 - accuracy: 0.5700 - val_loss: 0.0224 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 60/100\n72/72 - 6s - loss: 0.0010 - accuracy: 0.5631 - val_loss: 0.0222 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 61/100\n72/72 - 6s - loss: 0.0018 - accuracy: 0.5486 - val_loss: 0.0221 - val_accuracy: 0.5800 - 6s/epoch - 86ms/step\nEpoch 62/100\n72/72 - 6s - loss: 0.0016 - accuracy: 0.5528 - val_loss: 0.0632 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 63/100\n72/72 - 6s - loss: 0.0015 - accuracy: 0.5481 - val_loss: 0.0677 - val_accuracy: 0.5100 - 6s/epoch - 86ms/step\nEpoch 64/100\n72/72 - 6s - loss: 0.0020 - accuracy: 0.5483 - val_loss: 0.0396 - val_accuracy: 0.5350 - 6s/epoch - 86ms/step\nEpoch 65/100\n72/72 - 6s - loss: 0.0026 - accuracy: 0.5481 - val_loss: 0.0359 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 66/100\n72/72 - 6s - loss: 0.0013 - accuracy: 0.5575 - val_loss: 0.1065 - val_accuracy: 0.5150 - 6s/epoch - 86ms/step\nEpoch 67/100\n72/72 - 6s - loss: 0.0018 - accuracy: 0.5522 - val_loss: 0.0324 - val_accuracy: 0.5825 - 6s/epoch - 87ms/step\nEpoch 68/100\n72/72 - 6s - loss: 9.4867e-04 - accuracy: 0.5631 - val_loss: 0.0266 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 69/100\n72/72 - 6s - loss: 0.0011 - accuracy: 0.5619 - val_loss: 0.0161 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 70/100\n72/72 - 6s - loss: 8.7286e-04 - accuracy: 0.5528 - val_loss: 0.0178 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 71/100\n72/72 - 6s - loss: 7.5650e-04 - accuracy: 0.5508 - val_loss: 0.0438 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 72/100\n72/72 - 6s - loss: 8.1098e-04 - accuracy: 0.5697 - val_loss: 0.0196 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 73/100\n72/72 - 6s - loss: 7.9632e-04 - accuracy: 0.5608 - val_loss: 0.0244 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 74/100\n72/72 - 6s - loss: 5.1040e-04 - accuracy: 0.5683 - val_loss: 0.0360 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 75/100\n72/72 - 6s - loss: 0.0016 - accuracy: 0.5597 - val_loss: 0.0340 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 76/100\n72/72 - 6s - loss: 7.6846e-04 - accuracy: 0.5594 - val_loss: 0.0306 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 77/100\n72/72 - 6s - loss: 9.0025e-04 - accuracy: 0.5633 - val_loss: 0.0211 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 78/100\n72/72 - 6s - loss: 6.6559e-04 - accuracy: 0.5581 - val_loss: 0.0173 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 79/100\n72/72 - 6s - loss: 6.8665e-04 - accuracy: 0.5592 - val_loss: 0.0269 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 80/100\n72/72 - 6s - loss: 5.7490e-04 - accuracy: 0.5622 - val_loss: 0.0244 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 81/100\n72/72 - 6s - loss: 5.8953e-04 - accuracy: 0.5664 - val_loss: 0.0325 - val_accuracy: 0.5150 - 6s/epoch - 86ms/step\nEpoch 82/100\n72/72 - 6s - loss: 8.7475e-04 - accuracy: 0.5575 - val_loss: 0.0448 - val_accuracy: 0.5775 - 6s/epoch - 88ms/step\nEpoch 83/100\n72/72 - 6s - loss: 6.6892e-04 - accuracy: 0.5692 - val_loss: 0.0171 - val_accuracy: 0.5125 - 6s/epoch - 88ms/step\nEpoch 84/100\n72/72 - 6s - loss: 7.2507e-04 - accuracy: 0.5819 - val_loss: 0.0211 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 85/100\n72/72 - 6s - loss: 9.2390e-04 - accuracy: 0.5769 - val_loss: 0.0343 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 86/100\n72/72 - 6s - loss: 4.3540e-04 - accuracy: 0.5669 - val_loss: 0.0157 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 87/100\n72/72 - 6s - loss: 1.7524e-04 - accuracy: 0.5631 - val_loss: 0.0137 - val_accuracy: 0.5600 - 6s/epoch - 88ms/step\nEpoch 88/100\n72/72 - 6s - loss: 3.4094e-04 - accuracy: 0.5697 - val_loss: 0.0229 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 89/100\n72/72 - 6s - loss: 5.4249e-04 - accuracy: 0.5597 - val_loss: 0.0238 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 90/100\n72/72 - 6s - loss: 5.4264e-04 - accuracy: 0.5619 - val_loss: 0.0229 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 91/100\n72/72 - 6s - loss: 6.1614e-04 - accuracy: 0.5689 - val_loss: 0.0111 - val_accuracy: 0.5175 - 6s/epoch - 87ms/step\nEpoch 92/100\n72/72 - 6s - loss: 3.3521e-04 - accuracy: 0.5686 - val_loss: 0.0222 - val_accuracy: 0.5275 - 6s/epoch - 88ms/step\nEpoch 93/100\n72/72 - 6s - loss: 4.5393e-04 - accuracy: 0.5606 - val_loss: 0.0194 - val_accuracy: 0.5225 - 6s/epoch - 87ms/step\nEpoch 94/100\n72/72 - 6s - loss: 3.6189e-04 - accuracy: 0.5642 - val_loss: 0.0122 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 95/100\n72/72 - 6s - loss: 2.4694e-04 - accuracy: 0.5675 - val_loss: 0.0249 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 96/100\n72/72 - 6s - loss: 3.2379e-04 - accuracy: 0.5667 - val_loss: 0.0175 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 97/100\n72/72 - 6s - loss: 1.8349e-04 - accuracy: 0.5656 - val_loss: 0.0103 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 98/100\n72/72 - 6s - loss: 9.8482e-05 - accuracy: 0.5625 - val_loss: 0.0079 - val_accuracy: 0.5425 - 6s/epoch - 88ms/step\nEpoch 99/100\n72/72 - 6s - loss: 2.4418e-04 - accuracy: 0.5536 - val_loss: 0.0270 - val_accuracy: 0.5150 - 6s/epoch - 87ms/step\nEpoch 100/100\n72/72 - 6s - loss: 1.8000e-04 - accuracy: 0.5600 - val_loss: 0.0133 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 1/100\n72/72 - 6s - loss: 0.0033 - accuracy: 0.5658 - val_loss: 0.0011 - val_accuracy: 0.5575 - 6s/epoch - 88ms/step\nEpoch 2/100\n72/72 - 6s - loss: 0.0057 - accuracy: 0.5539 - val_loss: 0.0134 - val_accuracy: 0.5725 - 6s/epoch - 87ms/step\nEpoch 3/100\n72/72 - 6s - loss: 0.0068 - accuracy: 0.5475 - val_loss: 0.0179 - val_accuracy: 0.6275 - 6s/epoch - 86ms/step\nEpoch 4/100\n72/72 - 6s - loss: 0.0065 - accuracy: 0.5547 - val_loss: 0.0066 - val_accuracy: 0.5700 - 6s/epoch - 87ms/step\nEpoch 5/100\n72/72 - 6s - loss: 0.0033 - accuracy: 0.5556 - val_loss: 0.0036 - val_accuracy: 0.5650 - 6s/epoch - 85ms/step\nEpoch 6/100\n72/72 - 6s - loss: 0.0030 - accuracy: 0.5553 - val_loss: 0.0061 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 7/100\n72/72 - 6s - loss: 0.0018 - accuracy: 0.5611 - val_loss: 0.0029 - val_accuracy: 0.5725 - 6s/epoch - 87ms/step\nEpoch 8/100\n72/72 - 6s - loss: 0.0018 - accuracy: 0.5572 - val_loss: 0.0132 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 9/100\n72/72 - 6s - loss: 0.0020 - accuracy: 0.5522 - val_loss: 0.0352 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 10/100\n72/72 - 6s - loss: 0.0025 - accuracy: 0.5481 - val_loss: 0.0074 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 11/100\n72/72 - 6s - loss: 0.0025 - accuracy: 0.5536 - val_loss: 0.0061 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 12/100\n72/72 - 6s - loss: 0.0013 - accuracy: 0.5525 - val_loss: 0.0148 - val_accuracy: 0.5925 - 6s/epoch - 88ms/step\nEpoch 13/100\n72/72 - 6s - loss: 0.0015 - accuracy: 0.5519 - val_loss: 8.2204e-04 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 14/100\n72/72 - 6s - loss: 0.0014 - accuracy: 0.5539 - val_loss: 6.4955e-04 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 15/100\n72/72 - 6s - loss: 0.0024 - accuracy: 0.5631 - val_loss: 0.0047 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 16/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5575 - val_loss: 0.0058 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 17/100\n72/72 - 6s - loss: 0.0018 - accuracy: 0.5561 - val_loss: 0.0026 - val_accuracy: 0.6100 - 6s/epoch - 88ms/step\nEpoch 18/100\n72/72 - 6s - loss: 0.0015 - accuracy: 0.5494 - val_loss: 8.7595e-04 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 19/100\n72/72 - 6s - loss: 9.5297e-04 - accuracy: 0.5578 - val_loss: 0.0053 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 20/100\n72/72 - 6s - loss: 9.1175e-04 - accuracy: 0.5481 - val_loss: 0.0040 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 21/100\n72/72 - 6s - loss: 0.0014 - accuracy: 0.5567 - val_loss: 0.0291 - val_accuracy: 0.6150 - 6s/epoch - 86ms/step\nEpoch 22/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5564 - val_loss: 0.0028 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 23/100\n72/72 - 6s - loss: 0.0013 - accuracy: 0.5608 - val_loss: 8.5423e-04 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 24/100\n72/72 - 6s - loss: 7.8715e-04 - accuracy: 0.5675 - val_loss: 0.0011 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 25/100\n72/72 - 6s - loss: 9.1843e-04 - accuracy: 0.5717 - val_loss: 0.0056 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 26/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5661 - val_loss: 0.0024 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 27/100\n72/72 - 6s - loss: 0.0020 - accuracy: 0.5611 - val_loss: 0.0164 - val_accuracy: 0.5350 - 6s/epoch - 87ms/step\nEpoch 28/100\n72/72 - 6s - loss: 0.0022 - accuracy: 0.5669 - val_loss: 0.0037 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 29/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5661 - val_loss: 0.0038 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 30/100\n72/72 - 6s - loss: 6.4853e-04 - accuracy: 0.5744 - val_loss: 5.5512e-04 - val_accuracy: 0.5800 - 6s/epoch - 86ms/step\nEpoch 31/100\n72/72 - 6s - loss: 0.0011 - accuracy: 0.5647 - val_loss: 0.0078 - val_accuracy: 0.5900 - 6s/epoch - 86ms/step\nEpoch 32/100\n72/72 - 6s - loss: 0.0014 - accuracy: 0.5683 - val_loss: 0.0062 - val_accuracy: 0.6025 - 6s/epoch - 87ms/step\nEpoch 33/100\n72/72 - 6s - loss: 8.1552e-04 - accuracy: 0.5650 - val_loss: 0.0014 - val_accuracy: 0.5825 - 6s/epoch - 87ms/step\nEpoch 34/100\n72/72 - 6s - loss: 0.0010 - accuracy: 0.5547 - val_loss: 0.0268 - val_accuracy: 0.6550 - 6s/epoch - 86ms/step\nEpoch 35/100\n72/72 - 6s - loss: 5.6896e-04 - accuracy: 0.5642 - val_loss: 0.0097 - val_accuracy: 0.5925 - 6s/epoch - 85ms/step\nEpoch 36/100\n72/72 - 6s - loss: 0.0010 - accuracy: 0.5694 - val_loss: 0.0031 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 37/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5681 - val_loss: 0.0202 - val_accuracy: 0.6150 - 6s/epoch - 87ms/step\nEpoch 38/100\n72/72 - 6s - loss: 9.1574e-04 - accuracy: 0.5644 - val_loss: 0.0073 - val_accuracy: 0.5800 - 6s/epoch - 86ms/step\nEpoch 39/100\n72/72 - 6s - loss: 8.0315e-04 - accuracy: 0.5539 - val_loss: 0.0016 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 40/100\n72/72 - 6s - loss: 0.0016 - accuracy: 0.5547 - val_loss: 0.0021 - val_accuracy: 0.5775 - 6s/epoch - 85ms/step\nEpoch 41/100\n72/72 - 6s - loss: 0.0015 - accuracy: 0.5608 - val_loss: 0.0025 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 42/100\n72/72 - 6s - loss: 8.7628e-04 - accuracy: 0.5578 - val_loss: 0.0028 - val_accuracy: 0.5450 - 6s/epoch - 85ms/step\nEpoch 43/100\n72/72 - 6s - loss: 0.0010 - accuracy: 0.5597 - val_loss: 0.0021 - val_accuracy: 0.5725 - 6s/epoch - 87ms/step\nEpoch 44/100\n72/72 - 6s - loss: 7.7135e-04 - accuracy: 0.5678 - val_loss: 0.0032 - val_accuracy: 0.5825 - 6s/epoch - 86ms/step\nEpoch 45/100\n72/72 - 6s - loss: 9.6803e-04 - accuracy: 0.5697 - val_loss: 0.0100 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 46/100\n72/72 - 6s - loss: 0.0015 - accuracy: 0.5575 - val_loss: 0.0160 - val_accuracy: 0.6225 - 6s/epoch - 86ms/step\nEpoch 47/100\n72/72 - 6s - loss: 9.6733e-04 - accuracy: 0.5661 - val_loss: 0.0014 - val_accuracy: 0.5825 - 6s/epoch - 86ms/step\nEpoch 48/100\n72/72 - 6s - loss: 6.3678e-04 - accuracy: 0.5672 - val_loss: 0.0019 - val_accuracy: 0.5700 - 6s/epoch - 88ms/step\nEpoch 49/100\n72/72 - 6s - loss: 8.8699e-04 - accuracy: 0.5719 - val_loss: 0.0047 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 50/100\n72/72 - 6s - loss: 7.5446e-04 - accuracy: 0.5714 - val_loss: 0.0015 - val_accuracy: 0.5900 - 6s/epoch - 87ms/step\nEpoch 51/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5786 - val_loss: 0.0062 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 52/100\n72/72 - 6s - loss: 5.8486e-04 - accuracy: 0.5633 - val_loss: 8.2618e-04 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 53/100\n72/72 - 6s - loss: 8.3374e-04 - accuracy: 0.5581 - val_loss: 0.0067 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 54/100\n72/72 - 6s - loss: 5.1993e-04 - accuracy: 0.5728 - val_loss: 0.0020 - val_accuracy: 0.6050 - 6s/epoch - 86ms/step\nEpoch 55/100\n72/72 - 6s - loss: 7.0723e-04 - accuracy: 0.5689 - val_loss: 8.4447e-04 - val_accuracy: 0.6100 - 6s/epoch - 86ms/step\nEpoch 56/100\n72/72 - 6s - loss: 0.0036 - accuracy: 0.5706 - val_loss: 0.0135 - val_accuracy: 0.5325 - 6s/epoch - 85ms/step\nEpoch 57/100\n72/72 - 6s - loss: 0.0019 - accuracy: 0.5586 - val_loss: 0.0069 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 58/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5636 - val_loss: 0.0020 - val_accuracy: 0.5575 - 6s/epoch - 88ms/step\nEpoch 59/100\n72/72 - 6s - loss: 9.1428e-04 - accuracy: 0.5725 - val_loss: 0.0037 - val_accuracy: 0.5700 - 6s/epoch - 87ms/step\nEpoch 60/100\n72/72 - 6s - loss: 7.3829e-04 - accuracy: 0.5589 - val_loss: 0.0038 - val_accuracy: 0.5725 - 6s/epoch - 86ms/step\nEpoch 61/100\n72/72 - 6s - loss: 0.0010 - accuracy: 0.5667 - val_loss: 0.0064 - val_accuracy: 0.5925 - 6s/epoch - 87ms/step\nEpoch 62/100\n72/72 - 6s - loss: 8.9602e-04 - accuracy: 0.5686 - val_loss: 0.0087 - val_accuracy: 0.6300 - 6s/epoch - 86ms/step\nEpoch 63/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5742 - val_loss: 0.0067 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 64/100\n72/72 - 6s - loss: 6.8324e-04 - accuracy: 0.5742 - val_loss: 0.0063 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 65/100\n72/72 - 6s - loss: 6.2926e-04 - accuracy: 0.5656 - val_loss: 0.0077 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 66/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5744 - val_loss: 0.0074 - val_accuracy: 0.6200 - 6s/epoch - 86ms/step\nEpoch 67/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5581 - val_loss: 0.0159 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 68/100\n72/72 - 6s - loss: 0.0011 - accuracy: 0.5728 - val_loss: 0.0062 - val_accuracy: 0.5350 - 6s/epoch - 87ms/step\nEpoch 69/100\n72/72 - 6s - loss: 6.9118e-04 - accuracy: 0.5675 - val_loss: 0.0022 - val_accuracy: 0.5900 - 6s/epoch - 86ms/step\nEpoch 70/100\n72/72 - 6s - loss: 4.8247e-04 - accuracy: 0.5625 - val_loss: 0.0022 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 71/100\n72/72 - 6s - loss: 9.2485e-04 - accuracy: 0.5658 - val_loss: 0.0034 - val_accuracy: 0.5925 - 6s/epoch - 86ms/step\nEpoch 72/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5731 - val_loss: 0.0133 - val_accuracy: 0.6425 - 6s/epoch - 87ms/step\nEpoch 73/100\n72/72 - 6s - loss: 3.5815e-04 - accuracy: 0.5706 - val_loss: 0.0037 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 74/100\n72/72 - 6s - loss: 5.7205e-04 - accuracy: 0.5619 - val_loss: 0.0039 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 75/100\n72/72 - 6s - loss: 4.4746e-04 - accuracy: 0.5600 - val_loss: 0.0061 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 76/100\n72/72 - 6s - loss: 2.8839e-04 - accuracy: 0.5575 - val_loss: 0.0026 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 77/100\n72/72 - 6s - loss: 2.1316e-04 - accuracy: 0.5725 - val_loss: 9.9638e-04 - val_accuracy: 0.5725 - 6s/epoch - 87ms/step\nEpoch 78/100\n72/72 - 6s - loss: 1.7008e-04 - accuracy: 0.5714 - val_loss: 0.0021 - val_accuracy: 0.6175 - 6s/epoch - 87ms/step\nEpoch 79/100\n72/72 - 6s - loss: 1.9843e-04 - accuracy: 0.5861 - val_loss: 0.0014 - val_accuracy: 0.5750 - 6s/epoch - 87ms/step\nEpoch 80/100\n72/72 - 6s - loss: 1.5467e-04 - accuracy: 0.5850 - val_loss: 0.0014 - val_accuracy: 0.5925 - 6s/epoch - 87ms/step\nEpoch 81/100\n72/72 - 6s - loss: 4.7589e-04 - accuracy: 0.5747 - val_loss: 0.0020 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 82/100\n72/72 - 6s - loss: 8.1862e-04 - accuracy: 0.5672 - val_loss: 0.0028 - val_accuracy: 0.5600 - 6s/epoch - 85ms/step\nEpoch 83/100\n72/72 - 6s - loss: 2.8416e-04 - accuracy: 0.5611 - val_loss: 0.0020 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 84/100\n72/72 - 6s - loss: 3.8744e-04 - accuracy: 0.5614 - val_loss: 0.0020 - val_accuracy: 0.5750 - 6s/epoch - 88ms/step\nEpoch 85/100\n72/72 - 6s - loss: 6.4720e-04 - accuracy: 0.5578 - val_loss: 0.0017 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 86/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5589 - val_loss: 0.0024 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 87/100\n72/72 - 6s - loss: 2.8075e-04 - accuracy: 0.5719 - val_loss: 5.8359e-04 - val_accuracy: 0.5725 - 6s/epoch - 86ms/step\nEpoch 88/100\n72/72 - 6s - loss: 2.9478e-04 - accuracy: 0.5708 - val_loss: 0.0025 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 89/100\n72/72 - 6s - loss: 2.4409e-04 - accuracy: 0.5633 - val_loss: 0.0014 - val_accuracy: 0.5825 - 6s/epoch - 88ms/step\nEpoch 90/100\n72/72 - 6s - loss: 4.8654e-04 - accuracy: 0.5564 - val_loss: 0.0034 - val_accuracy: 0.6100 - 6s/epoch - 85ms/step\nEpoch 91/100\n72/72 - 6s - loss: 2.9232e-04 - accuracy: 0.5714 - val_loss: 0.0031 - val_accuracy: 0.5975 - 6s/epoch - 87ms/step\nEpoch 92/100\n72/72 - 6s - loss: 3.6926e-04 - accuracy: 0.5739 - val_loss: 0.0036 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 93/100\n72/72 - 6s - loss: 9.8145e-05 - accuracy: 0.5628 - val_loss: 0.0025 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 94/100\n72/72 - 6s - loss: 2.2499e-04 - accuracy: 0.5644 - val_loss: 0.0057 - val_accuracy: 0.5975 - 6s/epoch - 87ms/step\nEpoch 95/100\n72/72 - 6s - loss: 3.1167e-04 - accuracy: 0.5642 - val_loss: 0.0024 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 96/100\n72/72 - 6s - loss: 1.3342e-04 - accuracy: 0.5622 - val_loss: 0.0014 - val_accuracy: 0.5975 - 6s/epoch - 87ms/step\nEpoch 97/100\n72/72 - 6s - loss: 2.0221e-04 - accuracy: 0.5764 - val_loss: 0.0023 - val_accuracy: 0.5750 - 6s/epoch - 86ms/step\nEpoch 98/100\n72/72 - 6s - loss: 1.1309e-04 - accuracy: 0.5767 - val_loss: 0.0012 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 99/100\n72/72 - 6s - loss: 1.7392e-04 - accuracy: 0.5789 - val_loss: 0.0018 - val_accuracy: 0.5850 - 6s/epoch - 87ms/step\nEpoch 100/100\n72/72 - 6s - loss: 2.5627e-04 - accuracy: 0.5714 - val_loss: 0.0054 - val_accuracy: 0.5925 - 6s/epoch - 87ms/step\nEpoch 1/100\n72/72 - 6s - loss: 0.0013 - accuracy: 0.5778 - val_loss: 0.0052 - val_accuracy: 0.5600 - 6s/epoch - 88ms/step\nEpoch 2/100\n72/72 - 6s - loss: 0.0010 - accuracy: 0.5728 - val_loss: 0.0042 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 3/100\n72/72 - 6s - loss: 9.1244e-04 - accuracy: 0.5778 - val_loss: 3.7120e-04 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 4/100\n72/72 - 6s - loss: 6.5071e-04 - accuracy: 0.5831 - val_loss: 6.4998e-06 - val_accuracy: 0.5525 - 6s/epoch - 88ms/step\nEpoch 5/100\n72/72 - 6s - loss: 0.0026 - accuracy: 0.5653 - val_loss: 0.0569 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 6/100\n72/72 - 6s - loss: 0.0021 - accuracy: 0.5664 - val_loss: 4.0142e-04 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 7/100\n72/72 - 6s - loss: 9.8985e-04 - accuracy: 0.5642 - val_loss: 5.3991e-05 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 8/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5692 - val_loss: 0.0027 - val_accuracy: 0.5925 - 6s/epoch - 86ms/step\nEpoch 9/100\n72/72 - 6s - loss: 0.0024 - accuracy: 0.5822 - val_loss: 0.0159 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 10/100\n72/72 - 6s - loss: 0.0020 - accuracy: 0.5783 - val_loss: 0.0010 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 11/100\n72/72 - 6s - loss: 0.0019 - accuracy: 0.5725 - val_loss: 0.0011 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 12/100\n72/72 - 6s - loss: 0.0014 - accuracy: 0.5597 - val_loss: 0.0064 - val_accuracy: 0.5225 - 6s/epoch - 87ms/step\nEpoch 13/100\n72/72 - 6s - loss: 0.0030 - accuracy: 0.5742 - val_loss: 0.0013 - val_accuracy: 0.5875 - 6s/epoch - 87ms/step\nEpoch 14/100\n72/72 - 6s - loss: 0.0013 - accuracy: 0.5653 - val_loss: 0.0048 - val_accuracy: 0.5675 - 6s/epoch - 88ms/step\nEpoch 15/100\n72/72 - 6s - loss: 0.0013 - accuracy: 0.5628 - val_loss: 5.4487e-04 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 16/100\n72/72 - 6s - loss: 0.0014 - accuracy: 0.5539 - val_loss: 0.0023 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 17/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5622 - val_loss: 0.0021 - val_accuracy: 0.5825 - 6s/epoch - 86ms/step\nEpoch 18/100\n72/72 - 6s - loss: 0.0011 - accuracy: 0.5686 - val_loss: 0.0050 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 19/100\n72/72 - 6s - loss: 0.0010 - accuracy: 0.5669 - val_loss: 5.3720e-04 - val_accuracy: 0.5650 - 6s/epoch - 88ms/step\nEpoch 20/100\n72/72 - 6s - loss: 0.0023 - accuracy: 0.5811 - val_loss: 0.0026 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 21/100\n72/72 - 6s - loss: 9.2928e-04 - accuracy: 0.5650 - val_loss: 0.0108 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 22/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5597 - val_loss: 0.0094 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 23/100\n72/72 - 6s - loss: 0.0010 - accuracy: 0.5556 - val_loss: 0.0028 - val_accuracy: 0.5250 - 6s/epoch - 86ms/step\nEpoch 24/100\n72/72 - 6s - loss: 3.8350e-04 - accuracy: 0.5683 - val_loss: 0.0012 - val_accuracy: 0.5750 - 6s/epoch - 87ms/step\nEpoch 25/100\n72/72 - 6s - loss: 4.8035e-04 - accuracy: 0.5758 - val_loss: 1.5014e-04 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 26/100\n72/72 - 6s - loss: 6.7481e-04 - accuracy: 0.5753 - val_loss: 0.0020 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 27/100\n72/72 - 6s - loss: 5.3768e-04 - accuracy: 0.5600 - val_loss: 4.4567e-04 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 28/100\n72/72 - 6s - loss: 3.8220e-04 - accuracy: 0.5561 - val_loss: 2.7119e-04 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 29/100\n72/72 - 6s - loss: 4.6580e-04 - accuracy: 0.5614 - val_loss: 7.5406e-04 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 30/100\n72/72 - 6s - loss: 4.4765e-04 - accuracy: 0.5681 - val_loss: 2.9137e-04 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 31/100\n72/72 - 6s - loss: 4.1510e-04 - accuracy: 0.5692 - val_loss: 0.0015 - val_accuracy: 0.5750 - 6s/epoch - 86ms/step\nEpoch 32/100\n72/72 - 6s - loss: 2.8691e-04 - accuracy: 0.5672 - val_loss: 3.8478e-04 - val_accuracy: 0.5825 - 6s/epoch - 87ms/step\nEpoch 33/100\n72/72 - 6s - loss: 4.2626e-04 - accuracy: 0.5722 - val_loss: 0.0021 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 34/100\n72/72 - 6s - loss: 7.0852e-04 - accuracy: 0.5717 - val_loss: 3.0101e-04 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 35/100\n72/72 - 6s - loss: 3.7790e-04 - accuracy: 0.5631 - val_loss: 0.0013 - val_accuracy: 0.5325 - 6s/epoch - 87ms/step\nEpoch 36/100\n72/72 - 6s - loss: 8.6623e-04 - accuracy: 0.5619 - val_loss: 2.2755e-04 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 37/100\n72/72 - 6s - loss: 2.6703e-04 - accuracy: 0.5692 - val_loss: 6.9797e-04 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 38/100\n72/72 - 6s - loss: 2.7018e-04 - accuracy: 0.5569 - val_loss: 3.8654e-04 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 39/100\n72/72 - 6s - loss: 3.1467e-04 - accuracy: 0.5600 - val_loss: 0.0021 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 40/100\n72/72 - 6s - loss: 7.5390e-04 - accuracy: 0.5675 - val_loss: 0.0017 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 41/100\n72/72 - 6s - loss: 6.9516e-04 - accuracy: 0.5722 - val_loss: 0.0013 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 42/100\n72/72 - 6s - loss: 3.2882e-04 - accuracy: 0.5719 - val_loss: 2.4104e-04 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 43/100\n72/72 - 6s - loss: 2.3773e-04 - accuracy: 0.5653 - val_loss: 2.5473e-04 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 44/100\n72/72 - 6s - loss: 4.2120e-04 - accuracy: 0.5583 - val_loss: 0.0031 - val_accuracy: 0.5125 - 6s/epoch - 87ms/step\nEpoch 45/100\n72/72 - 6s - loss: 3.1618e-04 - accuracy: 0.5564 - val_loss: 4.8155e-04 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 46/100\n72/72 - 6s - loss: 2.6190e-04 - accuracy: 0.5550 - val_loss: 1.1587e-04 - val_accuracy: 0.5350 - 6s/epoch - 86ms/step\nEpoch 47/100\n72/72 - 6s - loss: 3.1783e-04 - accuracy: 0.5514 - val_loss: 6.6747e-04 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 48/100\n72/72 - 6s - loss: 8.3902e-04 - accuracy: 0.5558 - val_loss: 0.0015 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 49/100\n72/72 - 6s - loss: 7.6282e-05 - accuracy: 0.5539 - val_loss: 7.4016e-05 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 52/100\n72/72 - 6s - loss: 2.6088e-04 - accuracy: 0.5658 - val_loss: 1.8953e-04 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 53/100\n72/72 - 6s - loss: 3.5203e-04 - accuracy: 0.5625 - val_loss: 9.0449e-04 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 54/100\n72/72 - 6s - loss: 1.0017e-04 - accuracy: 0.5658 - val_loss: 7.3615e-05 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 55/100\n72/72 - 6s - loss: 2.4153e-04 - accuracy: 0.5619 - val_loss: 2.2040e-04 - val_accuracy: 0.5350 - 6s/epoch - 88ms/step\n72/72 - 6s - loss: 3.4379e-04 - accuracy: 0.5628 - val_loss: 9.7331e-05 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 58/100\n72/72 - 6s - loss: 2.9488e-04 - accuracy: 0.5647 - val_loss: 0.0015 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 59/100\n72/72 - 6s - loss: 2.7947e-04 - accuracy: 0.5653 - val_loss: 4.3310e-04 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 60/100\n72/72 - 6s - loss: 3.6070e-04 - accuracy: 0.5664 - val_loss: 1.2769e-04 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 61/100\n72/72 - 6s - loss: 6.7959e-05 - accuracy: 0.5731 - val_loss: 8.8622e-05 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 62/100\n72/72 - 6s - loss: 1.3597e-04 - accuracy: 0.5681 - val_loss: 6.4451e-05 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 63/100\n72/72 - 6s - loss: 1.1215e-04 - accuracy: 0.5661 - val_loss: 1.2207e-04 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 64/100\n72/72 - 6s - loss: 8.6356e-05 - accuracy: 0.5742 - val_loss: 1.5492e-04 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 65/100\n72/72 - 6s - loss: 1.2598e-04 - accuracy: 0.5681 - val_loss: 4.0326e-05 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 66/100\n72/72 - 6s - loss: 2.3210e-04 - accuracy: 0.5642 - val_loss: 7.5739e-05 - val_accuracy: 0.5350 - 6s/epoch - 87ms/step\nEpoch 67/100\n72/72 - 6s - loss: 2.7210e-04 - accuracy: 0.5617 - val_loss: 0.0011 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 68/100\n72/72 - 6s - loss: 3.5252e-04 - accuracy: 0.5711 - val_loss: 2.9770e-04 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 69/100\n72/72 - 6s - loss: 6.5726e-04 - accuracy: 0.5719 - val_loss: 0.0010 - val_accuracy: 0.5750 - 6s/epoch - 86ms/step\nEpoch 70/100\n72/72 - 6s - loss: 4.1315e-04 - accuracy: 0.5708 - val_loss: 0.0012 - val_accuracy: 0.5300 - 6s/epoch - 89ms/step\nEpoch 71/100\n72/72 - 6s - loss: 6.2679e-04 - accuracy: 0.5625 - val_loss: 0.0031 - val_accuracy: 0.5175 - 6s/epoch - 87ms/step\nEpoch 72/100\n72/72 - 6s - loss: 6.1438e-04 - accuracy: 0.5633 - val_loss: 3.1921e-04 - val_accuracy: 0.5075 - 6s/epoch - 86ms/step\nEpoch 73/100\n72/72 - 6s - loss: 3.1367e-04 - accuracy: 0.5583 - val_loss: 0.0010 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 74/100\n72/72 - 6s - loss: 1.8225e-04 - accuracy: 0.5589 - val_loss: 4.8202e-04 - val_accuracy: 0.5350 - 6s/epoch - 86ms/step\nEpoch 75/100\n72/72 - 6s - loss: 8.6738e-04 - accuracy: 0.5550 - val_loss: 9.1562e-04 - val_accuracy: 0.5150 - 6s/epoch - 88ms/step\nEpoch 76/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5489 - val_loss: 0.0014 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 77/100\n72/72 - 6s - loss: 5.4767e-04 - accuracy: 0.5564 - val_loss: 0.0016 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 78/100\n72/72 - 6s - loss: 5.7663e-04 - accuracy: 0.5603 - val_loss: 0.0041 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 79/100\n72/72 - 6s - loss: 2.1503e-04 - accuracy: 0.5675 - val_loss: 0.0056 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 80/100\n72/72 - 6s - loss: 2.6530e-04 - accuracy: 0.5572 - val_loss: 0.0039 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 81/100\n72/72 - 6s - loss: 4.8265e-04 - accuracy: 0.5625 - val_loss: 0.0043 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 82/100\n72/72 - 6s - loss: 3.2907e-04 - accuracy: 0.5686 - val_loss: 0.0065 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 83/100\n72/72 - 6s - loss: 2.0666e-04 - accuracy: 0.5692 - val_loss: 0.0018 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 84/100\n72/72 - 6s - loss: 4.0346e-04 - accuracy: 0.5633 - val_loss: 0.0021 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 85/100\n72/72 - 6s - loss: 6.5048e-04 - accuracy: 0.5583 - val_loss: 0.0169 - val_accuracy: 0.5000 - 6s/epoch - 89ms/step\nEpoch 86/100\n72/72 - 6s - loss: 2.3354e-04 - accuracy: 0.5600 - val_loss: 0.0036 - val_accuracy: 0.5150 - 6s/epoch - 86ms/step\nEpoch 87/100\n72/72 - 6s - loss: 4.6829e-04 - accuracy: 0.5553 - val_loss: 0.0038 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 88/100\n72/72 - 6s - loss: 3.0077e-04 - accuracy: 0.5558 - val_loss: 0.0044 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 89/100\n72/72 - 6s - loss: 7.4356e-04 - accuracy: 0.5611 - val_loss: 0.0106 - val_accuracy: 0.5075 - 6s/epoch - 87ms/step\nEpoch 90/100\n72/72 - 6s - loss: 2.4648e-04 - accuracy: 0.5581 - val_loss: 0.0024 - val_accuracy: 0.5175 - 6s/epoch - 87ms/step\nEpoch 91/100\n72/72 - 6s - loss: 2.7042e-04 - accuracy: 0.5603 - val_loss: 0.0025 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 92/100\n72/72 - 6s - loss: 2.1350e-04 - accuracy: 0.5606 - val_loss: 0.0013 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 93/100\n72/72 - 6s - loss: 4.8490e-04 - accuracy: 0.5581 - val_loss: 0.0334 - val_accuracy: 0.5125 - 6s/epoch - 87ms/step\nEpoch 94/100\n72/72 - 6s - loss: 7.3981e-04 - accuracy: 0.5678 - val_loss: 0.0040 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 95/100\n72/72 - 6s - loss: 5.4820e-04 - accuracy: 0.5608 - val_loss: 0.0068 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 96/100\n72/72 - 6s - loss: 3.5660e-04 - accuracy: 0.5622 - val_loss: 0.0037 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 97/100\n72/72 - 6s - loss: 3.5729e-04 - accuracy: 0.5581 - val_loss: 0.0038 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 98/100\n72/72 - 6s - loss: 0.0014 - accuracy: 0.5522 - val_loss: 0.0231 - val_accuracy: 0.5300 - 6s/epoch - 86ms/step\nEpoch 99/100\n72/72 - 6s - loss: 5.1473e-04 - accuracy: 0.5686 - val_loss: 0.0136 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 100/100\n72/72 - 6s - loss: 3.0436e-04 - accuracy: 0.5664 - val_loss: 0.0120 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 1/100\n72/72 - 6s - loss: 9.3752e-04 - accuracy: 0.5608 - val_loss: 0.0125 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 2/100\n72/72 - 6s - loss: 9.0963e-04 - accuracy: 0.5492 - val_loss: 0.0064 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 3/100\n72/72 - 6s - loss: 9.0796e-04 - accuracy: 0.5447 - val_loss: 0.0151 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 4/100\n72/72 - 6s - loss: 6.5534e-04 - accuracy: 0.5544 - val_loss: 0.0035 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 5/100\n72/72 - 6s - loss: 3.0682e-04 - accuracy: 0.5656 - val_loss: 0.0030 - val_accuracy: 0.5775 - 6s/epoch - 87ms/step\nEpoch 6/100\n72/72 - 6s - loss: 4.0231e-04 - accuracy: 0.5583 - val_loss: 0.0049 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 7/100\n72/72 - 6s - loss: 4.3591e-04 - accuracy: 0.5583 - val_loss: 0.0019 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 8/100\n72/72 - 6s - loss: 8.2568e-04 - accuracy: 0.5525 - val_loss: 0.0017 - val_accuracy: 0.6100 - 6s/epoch - 86ms/step\nEpoch 9/100\n72/72 - 6s - loss: 2.2915e-04 - accuracy: 0.5575 - val_loss: 0.0016 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 10/100\n72/72 - 6s - loss: 7.3165e-04 - accuracy: 0.5567 - val_loss: 0.0343 - val_accuracy: 0.5800 - 6s/epoch - 88ms/step\nEpoch 11/100\n72/72 - 6s - loss: 7.7530e-04 - accuracy: 0.5581 - val_loss: 0.0028 - val_accuracy: 0.5725 - 6s/epoch - 86ms/step\nEpoch 12/100\n72/72 - 6s - loss: 4.7945e-04 - accuracy: 0.5564 - val_loss: 0.0016 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 13/100\n72/72 - 6s - loss: 3.6376e-04 - accuracy: 0.5503 - val_loss: 1.5441e-04 - val_accuracy: 0.5825 - 6s/epoch - 87ms/step\nEpoch 14/100\n72/72 - 6s - loss: 3.8117e-04 - accuracy: 0.5625 - val_loss: 1.8092e-04 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 15/100\n72/72 - 6s - loss: 7.5628e-04 - accuracy: 0.5667 - val_loss: 0.0017 - val_accuracy: 0.5950 - 6s/epoch - 88ms/step\nEpoch 16/100\n72/72 - 6s - loss: 3.1529e-04 - accuracy: 0.5614 - val_loss: 7.3686e-04 - val_accuracy: 0.6150 - 6s/epoch - 85ms/step\nEpoch 17/100\n72/72 - 6s - loss: 3.4968e-04 - accuracy: 0.5786 - val_loss: 0.0011 - val_accuracy: 0.6075 - 6s/epoch - 87ms/step\nEpoch 18/100\n72/72 - 6s - loss: 2.7609e-04 - accuracy: 0.5678 - val_loss: 4.7962e-04 - val_accuracy: 0.6075 - 6s/epoch - 86ms/step\nEpoch 19/100\n72/72 - 6s - loss: 3.5203e-04 - accuracy: 0.5628 - val_loss: 0.0108 - val_accuracy: 0.6350 - 6s/epoch - 86ms/step\nEpoch 20/100\n72/72 - 6s - loss: 1.6088e-04 - accuracy: 0.5644 - val_loss: 0.0070 - val_accuracy: 0.6175 - 6s/epoch - 87ms/step\nEpoch 21/100\n72/72 - 6s - loss: 1.6203e-04 - accuracy: 0.5644 - val_loss: 0.0081 - val_accuracy: 0.6200 - 6s/epoch - 86ms/step\nEpoch 22/100\n72/72 - 6s - loss: 1.4374e-04 - accuracy: 0.5636 - val_loss: 0.0050 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 23/100\n72/72 - 6s - loss: 1.8527e-04 - accuracy: 0.5619 - val_loss: 0.0045 - val_accuracy: 0.5925 - 6s/epoch - 86ms/step\nEpoch 24/100\n72/72 - 6s - loss: 2.8461e-04 - accuracy: 0.5611 - val_loss: 0.0020 - val_accuracy: 0.6075 - 6s/epoch - 86ms/step\nEpoch 25/100\n72/72 - 6s - loss: 4.1879e-04 - accuracy: 0.5692 - val_loss: 0.0060 - val_accuracy: 0.6025 - 6s/epoch - 87ms/step\nEpoch 26/100\n72/72 - 6s - loss: 2.5100e-04 - accuracy: 0.5581 - val_loss: 0.0052 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 27/100\n72/72 - 6s - loss: 5.1577e-04 - accuracy: 0.5553 - val_loss: 0.0122 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 28/100\n72/72 - 6s - loss: 4.2884e-04 - accuracy: 0.5608 - val_loss: 0.0038 - val_accuracy: 0.6100 - 6s/epoch - 87ms/step\nEpoch 29/100\n72/72 - 6s - loss: 3.2769e-04 - accuracy: 0.5669 - val_loss: 0.0067 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 30/100\n72/72 - 6s - loss: 1.6483e-04 - accuracy: 0.5603 - val_loss: 0.0033 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 31/100\n72/72 - 6s - loss: 2.4829e-04 - accuracy: 0.5608 - val_loss: 0.0053 - val_accuracy: 0.5925 - 6s/epoch - 86ms/step\nEpoch 32/100\n72/72 - 6s - loss: 2.9354e-04 - accuracy: 0.5667 - val_loss: 0.0032 - val_accuracy: 0.6125 - 6s/epoch - 87ms/step\nEpoch 33/100\n72/72 - 6s - loss: 0.0011 - accuracy: 0.5692 - val_loss: 0.0031 - val_accuracy: 0.6175 - 6s/epoch - 86ms/step\nEpoch 34/100\n72/72 - 6s - loss: 1.8506e-04 - accuracy: 0.5669 - val_loss: 0.0033 - val_accuracy: 0.5875 - 6s/epoch - 87ms/step\nEpoch 35/100\n72/72 - 6s - loss: 3.2784e-04 - accuracy: 0.5736 - val_loss: 0.0030 - val_accuracy: 0.5950 - 6s/epoch - 88ms/step\nEpoch 36/100\n72/72 - 6s - loss: 4.9427e-04 - accuracy: 0.5694 - val_loss: 0.0046 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 37/100\n72/72 - 6s - loss: 4.5340e-04 - accuracy: 0.5711 - val_loss: 0.0030 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 38/100\n72/72 - 6s - loss: 2.9379e-04 - accuracy: 0.5667 - val_loss: 0.0062 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 39/100\n72/72 - 6s - loss: 1.8255e-04 - accuracy: 0.5644 - val_loss: 0.0046 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 40/100\n72/72 - 6s - loss: 6.4692e-05 - accuracy: 0.5592 - val_loss: 0.0055 - val_accuracy: 0.5775 - 6s/epoch - 87ms/step\nEpoch 41/100\n72/72 - 6s - loss: 1.0664e-04 - accuracy: 0.5581 - val_loss: 0.0062 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 42/100\n72/72 - 6s - loss: 3.1827e-04 - accuracy: 0.5578 - val_loss: 0.0066 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 43/100\n72/72 - 6s - loss: 4.8837e-04 - accuracy: 0.5528 - val_loss: 0.0023 - val_accuracy: 0.5875 - 6s/epoch - 87ms/step\nEpoch 44/100\n72/72 - 6s - loss: 3.8263e-04 - accuracy: 0.5572 - val_loss: 0.0077 - val_accuracy: 0.5850 - 6s/epoch - 87ms/step\nEpoch 45/100\n72/72 - 6s - loss: 1.8602e-04 - accuracy: 0.5525 - val_loss: 0.0090 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 46/100\n72/72 - 6s - loss: 4.6888e-04 - accuracy: 0.5542 - val_loss: 0.0048 - val_accuracy: 0.5900 - 6s/epoch - 87ms/step\nEpoch 47/100\n72/72 - 6s - loss: 4.6965e-04 - accuracy: 0.5569 - val_loss: 0.0119 - val_accuracy: 0.5750 - 6s/epoch - 86ms/step\nEpoch 48/100\n72/72 - 6s - loss: 3.2808e-04 - accuracy: 0.5544 - val_loss: 0.0127 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 49/100\n72/72 - 6s - loss: 2.3204e-04 - accuracy: 0.5469 - val_loss: 0.0091 - val_accuracy: 0.5925 - 6s/epoch - 87ms/step\nEpoch 50/100\n72/72 - 6s - loss: 2.6974e-04 - accuracy: 0.5506 - val_loss: 0.0091 - val_accuracy: 0.6050 - 6s/epoch - 88ms/step\nEpoch 51/100\n72/72 - 6s - loss: 3.3285e-04 - accuracy: 0.5586 - val_loss: 0.0068 - val_accuracy: 0.5925 - 6s/epoch - 87ms/step\nEpoch 52/100\n72/72 - 6s - loss: 2.5329e-04 - accuracy: 0.5556 - val_loss: 0.0067 - val_accuracy: 0.5725 - 6s/epoch - 86ms/step\nEpoch 53/100\n72/72 - 6s - loss: 8.2519e-05 - accuracy: 0.5511 - val_loss: 0.0058 - val_accuracy: 0.5775 - 6s/epoch - 87ms/step\nEpoch 54/100\n72/72 - 6s - loss: 2.1512e-04 - accuracy: 0.5531 - val_loss: 0.0048 - val_accuracy: 0.6050 - 6s/epoch - 86ms/step\nEpoch 55/100\n72/72 - 6s - loss: 2.0957e-04 - accuracy: 0.5575 - val_loss: 0.0066 - val_accuracy: 0.5775 - 6s/epoch - 87ms/step\nEpoch 56/100\n72/72 - 6s - loss: 1.9607e-04 - accuracy: 0.5539 - val_loss: 0.0064 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 57/100\n72/72 - 6s - loss: 5.6105e-05 - accuracy: 0.5519 - val_loss: 0.0064 - val_accuracy: 0.5825 - 6s/epoch - 87ms/step\nEpoch 58/100\n72/72 - 6s - loss: 2.5435e-04 - accuracy: 0.5528 - val_loss: 0.0084 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 59/100\n72/72 - 6s - loss: 2.6374e-04 - accuracy: 0.5497 - val_loss: 0.0272 - val_accuracy: 0.5850 - 6s/epoch - 87ms/step\nEpoch 60/100\n72/72 - 6s - loss: 1.1902e-04 - accuracy: 0.5483 - val_loss: 0.0211 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 61/100\n72/72 - 6s - loss: 8.4505e-05 - accuracy: 0.5461 - val_loss: 0.0145 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 62/100\n72/72 - 6s - loss: 5.6045e-05 - accuracy: 0.5483 - val_loss: 0.0155 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 63/100\n72/72 - 6s - loss: 1.1724e-04 - accuracy: 0.5458 - val_loss: 0.0269 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 64/100\n72/72 - 6s - loss: 7.6029e-05 - accuracy: 0.5481 - val_loss: 0.0110 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 65/100\n72/72 - 6s - loss: 1.7895e-04 - accuracy: 0.5439 - val_loss: 0.0188 - val_accuracy: 0.5850 - 6s/epoch - 87ms/step\nEpoch 66/100\n72/72 - 6s - loss: 3.8012e-05 - accuracy: 0.5481 - val_loss: 0.0227 - val_accuracy: 0.5875 - 6s/epoch - 88ms/step\nEpoch 67/100\n72/72 - 6s - loss: 1.9389e-04 - accuracy: 0.5558 - val_loss: 0.0170 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 68/100\n72/72 - 6s - loss: 7.7243e-05 - accuracy: 0.5567 - val_loss: 0.0145 - val_accuracy: 0.5800 - 6s/epoch - 86ms/step\nEpoch 69/100\n72/72 - 6s - loss: 2.9871e-04 - accuracy: 0.5569 - val_loss: 0.0148 - val_accuracy: 0.5325 - 6s/epoch - 87ms/step\nEpoch 70/100\n72/72 - 6s - loss: 3.2826e-04 - accuracy: 0.5414 - val_loss: 0.0113 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 71/100\n72/72 - 6s - loss: 3.4843e-05 - accuracy: 0.5558 - val_loss: 0.0155 - val_accuracy: 0.5800 - 6s/epoch - 88ms/step\nEpoch 72/100\n72/72 - 6s - loss: 4.9540e-05 - accuracy: 0.5517 - val_loss: 0.0107 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 73/100\n72/72 - 6s - loss: 7.9185e-05 - accuracy: 0.5439 - val_loss: 0.0145 - val_accuracy: 0.5725 - 6s/epoch - 86ms/step\nEpoch 74/100\n72/72 - 6s - loss: 1.2631e-04 - accuracy: 0.5531 - val_loss: 0.0096 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 75/100\n72/72 - 6s - loss: 3.9583e-05 - accuracy: 0.5486 - val_loss: 0.0077 - val_accuracy: 0.5850 - 6s/epoch - 87ms/step\nEpoch 76/100\n72/72 - 6s - loss: 3.7099e-04 - accuracy: 0.5486 - val_loss: 0.0048 - val_accuracy: 0.5900 - 6s/epoch - 87ms/step\nEpoch 77/100\n72/72 - 6s - loss: 3.1030e-05 - accuracy: 0.5500 - val_loss: 0.0098 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 78/100\n72/72 - 6s - loss: 1.4843e-04 - accuracy: 0.5556 - val_loss: 0.0065 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 79/100\n72/72 - 6s - loss: 2.4560e-04 - accuracy: 0.5536 - val_loss: 0.0122 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 80/100\n72/72 - 6s - loss: 8.0690e-05 - accuracy: 0.5603 - val_loss: 0.0092 - val_accuracy: 0.5800 - 6s/epoch - 86ms/step\nEpoch 81/100\n72/72 - 6s - loss: 2.2862e-04 - accuracy: 0.5608 - val_loss: 0.0054 - val_accuracy: 0.6300 - 6s/epoch - 88ms/step\nEpoch 82/100\n72/72 - 6s - loss: 1.3195e-04 - accuracy: 0.5653 - val_loss: 0.0116 - val_accuracy: 0.6200 - 6s/epoch - 86ms/step\nEpoch 83/100\n72/72 - 6s - loss: 2.1794e-04 - accuracy: 0.5622 - val_loss: 0.0116 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 84/100\n72/72 - 6s - loss: 1.0015e-04 - accuracy: 0.5625 - val_loss: 0.0101 - val_accuracy: 0.5950 - 6s/epoch - 86ms/step\nEpoch 85/100\n72/72 - 6s - loss: 3.7682e-05 - accuracy: 0.5592 - val_loss: 0.0055 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 86/100\n72/72 - 6s - loss: 1.6997e-04 - accuracy: 0.5586 - val_loss: 0.0022 - val_accuracy: 0.5900 - 6s/epoch - 88ms/step\nEpoch 87/100\n72/72 - 6s - loss: 2.3536e-04 - accuracy: 0.5536 - val_loss: 0.0086 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 88/100\n72/72 - 6s - loss: 7.9454e-05 - accuracy: 0.5561 - val_loss: 0.0108 - val_accuracy: 0.5900 - 6s/epoch - 86ms/step\nEpoch 89/100\n72/72 - 6s - loss: 4.4326e-05 - accuracy: 0.5558 - val_loss: 0.0156 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 90/100\n72/72 - 6s - loss: 1.4826e-04 - accuracy: 0.5486 - val_loss: 0.0106 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 91/100\n72/72 - 6s - loss: 1.3121e-04 - accuracy: 0.5608 - val_loss: 0.0086 - val_accuracy: 0.5950 - 6s/epoch - 86ms/step\nEpoch 92/100\n72/72 - 6s - loss: 3.3056e-04 - accuracy: 0.5544 - val_loss: 0.0132 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 93/100\n72/72 - 6s - loss: 7.1988e-05 - accuracy: 0.5556 - val_loss: 0.0069 - val_accuracy: 0.5800 - 6s/epoch - 86ms/step\nEpoch 94/100\n72/72 - 6s - loss: 1.0177e-04 - accuracy: 0.5592 - val_loss: 0.0056 - val_accuracy: 0.5925 - 6s/epoch - 87ms/step\nEpoch 95/100\n72/72 - 6s - loss: 4.7866e-05 - accuracy: 0.5589 - val_loss: 0.0084 - val_accuracy: 0.5975 - 6s/epoch - 86ms/step\nEpoch 96/100\n72/72 - 6s - loss: 8.7562e-05 - accuracy: 0.5600 - val_loss: 0.0086 - val_accuracy: 0.5875 - 6s/epoch - 88ms/step\nEpoch 97/100\n72/72 - 6s - loss: 1.0837e-04 - accuracy: 0.5650 - val_loss: 0.0050 - val_accuracy: 0.6100 - 6s/epoch - 86ms/step\nEpoch 98/100\n72/72 - 6s - loss: 8.9805e-04 - accuracy: 0.5500 - val_loss: 0.0037 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 99/100\n72/72 - 6s - loss: 1.8101e-04 - accuracy: 0.5456 - val_loss: 0.0072 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 100/100\n72/72 - 6s - loss: 2.0764e-04 - accuracy: 0.5508 - val_loss: 0.0087 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 1/100\n72/72 - 7s - loss: 4.3974e-04 - accuracy: 0.5603 - val_loss: 0.0032 - val_accuracy: 0.5475 - 7s/epoch - 90ms/step\nEpoch 2/100\n72/72 - 6s - loss: 1.6031e-04 - accuracy: 0.5550 - val_loss: 0.0028 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 3/100\n72/72 - 6s - loss: 3.1706e-04 - accuracy: 0.5536 - val_loss: 0.0036 - val_accuracy: 0.5100 - 6s/epoch - 86ms/step\nEpoch 4/100\n72/72 - 6s - loss: 8.4186e-04 - accuracy: 0.5503 - val_loss: 3.3953e-05 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 5/100\n72/72 - 6s - loss: 6.0601e-04 - accuracy: 0.5631 - val_loss: 2.6465e-04 - val_accuracy: 0.5050 - 6s/epoch - 86ms/step\nEpoch 6/100\n72/72 - 6s - loss: 4.5175e-04 - accuracy: 0.5589 - val_loss: 0.0018 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 7/100\n72/72 - 6s - loss: 4.8501e-04 - accuracy: 0.5625 - val_loss: 0.0013 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 8/100\n72/72 - 6s - loss: 1.9118e-04 - accuracy: 0.5603 - val_loss: 0.0027 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 9/100\n72/72 - 6s - loss: 3.6040e-04 - accuracy: 0.5667 - val_loss: 0.0026 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 10/100\n72/72 - 6s - loss: 3.1091e-04 - accuracy: 0.5644 - val_loss: 0.0053 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 11/100\n72/72 - 6s - loss: 1.7575e-04 - accuracy: 0.5528 - val_loss: 0.0052 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 12/100\n72/72 - 6s - loss: 1.7416e-04 - accuracy: 0.5536 - val_loss: 0.0021 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 13/100\n72/72 - 6s - loss: 1.3649e-04 - accuracy: 0.5553 - val_loss: 0.0069 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 14/100\n72/72 - 6s - loss: 1.5002e-04 - accuracy: 0.5583 - val_loss: 0.0077 - val_accuracy: 0.5050 - 6s/epoch - 86ms/step\nEpoch 15/100\n72/72 - 6s - loss: 2.1372e-04 - accuracy: 0.5447 - val_loss: 0.0091 - val_accuracy: 0.5175 - 6s/epoch - 86ms/step\nEpoch 16/100\n72/72 - 6s - loss: 2.7749e-04 - accuracy: 0.5658 - val_loss: 0.0031 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 17/100\n72/72 - 6s - loss: 4.8376e-05 - accuracy: 0.5636 - val_loss: 0.0037 - val_accuracy: 0.5600 - 6s/epoch - 88ms/step\nEpoch 18/100\n72/72 - 6s - loss: 1.3616e-04 - accuracy: 0.5656 - val_loss: 0.0036 - val_accuracy: 0.5050 - 6s/epoch - 87ms/step\nEpoch 19/100\n72/72 - 6s - loss: 8.6525e-05 - accuracy: 0.5642 - val_loss: 0.0036 - val_accuracy: 0.5125 - 6s/epoch - 88ms/step\nEpoch 20/100\n72/72 - 6s - loss: 3.6924e-04 - accuracy: 0.5667 - val_loss: 0.0029 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 21/100\n72/72 - 6s - loss: 2.9039e-04 - accuracy: 0.5556 - val_loss: 0.0055 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 22/100\n72/72 - 6s - loss: 1.5411e-04 - accuracy: 0.5639 - val_loss: 0.0051 - val_accuracy: 0.5400 - 6s/epoch - 88ms/step\nEpoch 23/100\n72/72 - 6s - loss: 8.3216e-05 - accuracy: 0.5642 - val_loss: 0.0048 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 24/100\n72/72 - 6s - loss: 1.5303e-04 - accuracy: 0.5592 - val_loss: 0.0070 - val_accuracy: 0.5175 - 6s/epoch - 86ms/step\nEpoch 25/100\n72/72 - 6s - loss: 3.5691e-04 - accuracy: 0.5550 - val_loss: 0.0058 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 26/100\n72/72 - 6s - loss: 1.4199e-04 - accuracy: 0.5636 - val_loss: 0.0038 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 27/100\n72/72 - 6s - loss: 1.1214e-04 - accuracy: 0.5597 - val_loss: 0.0037 - val_accuracy: 0.5275 - 6s/epoch - 88ms/step\nEpoch 28/100\n72/72 - 6s - loss: 6.9177e-05 - accuracy: 0.5653 - val_loss: 0.0044 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 29/100\n72/72 - 6s - loss: 8.6303e-05 - accuracy: 0.5611 - val_loss: 0.0027 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 30/100\n72/72 - 6s - loss: 3.8251e-05 - accuracy: 0.5650 - val_loss: 0.0029 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 31/100\n72/72 - 6s - loss: 8.9161e-05 - accuracy: 0.5550 - val_loss: 0.0044 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 32/100\n72/72 - 6s - loss: 3.5157e-04 - accuracy: 0.5667 - val_loss: 0.0025 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 33/100\n72/72 - 6s - loss: 2.7061e-04 - accuracy: 0.5700 - val_loss: 0.0037 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 34/100\n72/72 - 6s - loss: 2.5766e-04 - accuracy: 0.5622 - val_loss: 0.0027 - val_accuracy: 0.5250 - 6s/epoch - 85ms/step\nEpoch 35/100\n72/72 - 6s - loss: 1.8953e-04 - accuracy: 0.5617 - val_loss: 0.0047 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 36/100\n72/72 - 6s - loss: 3.0926e-04 - accuracy: 0.5669 - val_loss: 0.0051 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 37/100\n72/72 - 6s - loss: 4.0663e-04 - accuracy: 0.5642 - val_loss: 0.0043 - val_accuracy: 0.5325 - 6s/epoch - 87ms/step\nEpoch 38/100\n72/72 - 6s - loss: 2.5073e-04 - accuracy: 0.5642 - val_loss: 0.0050 - val_accuracy: 0.5350 - 6s/epoch - 86ms/step\nEpoch 39/100\n72/72 - 6s - loss: 4.3616e-04 - accuracy: 0.5669 - val_loss: 0.0042 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 40/100\n72/72 - 6s - loss: 3.3282e-04 - accuracy: 0.5644 - val_loss: 0.0043 - val_accuracy: 0.5050 - 6s/epoch - 87ms/step\nEpoch 41/100\n72/72 - 6s - loss: 1.9181e-04 - accuracy: 0.5608 - val_loss: 0.0031 - val_accuracy: 0.5250 - 6s/epoch - 86ms/step\nEpoch 42/100\n72/72 - 6s - loss: 2.4641e-04 - accuracy: 0.5625 - val_loss: 0.0050 - val_accuracy: 0.5225 - 6s/epoch - 87ms/step\nEpoch 43/100\n72/72 - 6s - loss: 2.8874e-04 - accuracy: 0.5617 - val_loss: 0.0033 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 44/100\n72/72 - 6s - loss: 4.7861e-05 - accuracy: 0.5553 - val_loss: 0.0038 - val_accuracy: 0.5300 - 6s/epoch - 86ms/step\nEpoch 45/100\n72/72 - 6s - loss: 8.2414e-05 - accuracy: 0.5625 - val_loss: 0.0045 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 46/100\n72/72 - 6s - loss: 4.7172e-05 - accuracy: 0.5597 - val_loss: 0.0053 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 47/100\n72/72 - 6s - loss: 4.0526e-04 - accuracy: 0.5622 - val_loss: 0.0015 - val_accuracy: 0.5100 - 6s/epoch - 87ms/step\nEpoch 48/100\n72/72 - 6s - loss: 2.1735e-04 - accuracy: 0.5578 - val_loss: 0.0049 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 49/100\n72/72 - 6s - loss: 0.0023 - accuracy: 0.5586 - val_loss: 0.0162 - val_accuracy: 0.4950 - 6s/epoch - 87ms/step\nEpoch 50/100\n72/72 - 6s - loss: 3.8571e-04 - accuracy: 0.5575 - val_loss: 0.0076 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 51/100\n72/72 - 6s - loss: 3.2651e-04 - accuracy: 0.5600 - val_loss: 0.0062 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 52/100\n72/72 - 6s - loss: 3.1789e-04 - accuracy: 0.5536 - val_loss: 0.0046 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 53/100\n72/72 - 6s - loss: 5.3680e-04 - accuracy: 0.5600 - val_loss: 0.0049 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 54/100\n72/72 - 6s - loss: 3.7679e-04 - accuracy: 0.5739 - val_loss: 0.0062 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 55/100\n72/72 - 6s - loss: 4.3417e-04 - accuracy: 0.5600 - val_loss: 0.0042 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 56/100\n72/72 - 6s - loss: 1.7943e-04 - accuracy: 0.5486 - val_loss: 0.0038 - val_accuracy: 0.5025 - 6s/epoch - 86ms/step\nEpoch 57/100\n72/72 - 6s - loss: 1.1981e-04 - accuracy: 0.5483 - val_loss: 0.0046 - val_accuracy: 0.5125 - 6s/epoch - 88ms/step\nEpoch 58/100\n72/72 - 6s - loss: 2.7316e-04 - accuracy: 0.5569 - val_loss: 0.0125 - val_accuracy: 0.5000 - 6s/epoch - 86ms/step\nEpoch 59/100\n72/72 - 6s - loss: 1.4178e-04 - accuracy: 0.5575 - val_loss: 0.0048 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 60/100\n72/72 - 6s - loss: 1.0151e-04 - accuracy: 0.5644 - val_loss: 0.0052 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 61/100\n72/72 - 6s - loss: 1.1452e-04 - accuracy: 0.5508 - val_loss: 0.0044 - val_accuracy: 0.5125 - 6s/epoch - 87ms/step\nEpoch 62/100\n72/72 - 6s - loss: 7.3042e-05 - accuracy: 0.5553 - val_loss: 0.0043 - val_accuracy: 0.5325 - 6s/epoch - 88ms/step\nEpoch 63/100\n72/72 - 6s - loss: 3.8151e-05 - accuracy: 0.5550 - val_loss: 0.0053 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 64/100\n72/72 - 6s - loss: 3.9307e-05 - accuracy: 0.5533 - val_loss: 0.0047 - val_accuracy: 0.5250 - 6s/epoch - 86ms/step\nEpoch 65/100\n72/72 - 6s - loss: 4.6766e-05 - accuracy: 0.5506 - val_loss: 0.0053 - val_accuracy: 0.5350 - 6s/epoch - 86ms/step\nEpoch 66/100\n72/72 - 6s - loss: 4.8185e-05 - accuracy: 0.5558 - val_loss: 0.0049 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 67/100\n72/72 - 6s - loss: 6.2852e-05 - accuracy: 0.5569 - val_loss: 0.0056 - val_accuracy: 0.5350 - 6s/epoch - 87ms/step\nEpoch 68/100\n72/72 - 6s - loss: 6.7048e-05 - accuracy: 0.5547 - val_loss: 0.0056 - val_accuracy: 0.5425 - 6s/epoch - 88ms/step\nEpoch 69/100\n72/72 - 6s - loss: 3.6229e-05 - accuracy: 0.5536 - val_loss: 0.0047 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 70/100\n72/72 - 6s - loss: 4.5931e-05 - accuracy: 0.5492 - val_loss: 0.0038 - val_accuracy: 0.5125 - 6s/epoch - 87ms/step\nEpoch 71/100\n72/72 - 6s - loss: 7.0918e-05 - accuracy: 0.5528 - val_loss: 0.0041 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 72/100\n72/72 - 6s - loss: 1.4922e-05 - accuracy: 0.5550 - val_loss: 0.0041 - val_accuracy: 0.5400 - 6s/epoch - 86ms/step\nEpoch 73/100\n72/72 - 6s - loss: 1.3808e-05 - accuracy: 0.5550 - val_loss: 0.0044 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 74/100\n72/72 - 6s - loss: 6.2650e-05 - accuracy: 0.5531 - val_loss: 0.0048 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 75/100\n72/72 - 6s - loss: 1.9704e-04 - accuracy: 0.5628 - val_loss: 0.0062 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 76/100\n72/72 - 6s - loss: 3.0091e-04 - accuracy: 0.5583 - val_loss: 0.0060 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 77/100\n72/72 - 6s - loss: 4.0010e-05 - accuracy: 0.5583 - val_loss: 0.0045 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 78/100\n72/72 - 6s - loss: 1.0506e-04 - accuracy: 0.5575 - val_loss: 0.0052 - val_accuracy: 0.5325 - 6s/epoch - 88ms/step\nEpoch 79/100\n72/72 - 6s - loss: 4.2423e-05 - accuracy: 0.5478 - val_loss: 0.0062 - val_accuracy: 0.5175 - 6s/epoch - 86ms/step\nEpoch 80/100\n72/72 - 6s - loss: 2.0830e-05 - accuracy: 0.5475 - val_loss: 0.0059 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 81/100\n72/72 - 6s - loss: 1.5834e-05 - accuracy: 0.5536 - val_loss: 0.0061 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 82/100\n72/72 - 6s - loss: 1.6213e-05 - accuracy: 0.5508 - val_loss: 0.0057 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 83/100\n72/72 - 6s - loss: 1.8103e-05 - accuracy: 0.5506 - val_loss: 0.0061 - val_accuracy: 0.5225 - 6s/epoch - 87ms/step\nEpoch 84/100\n72/72 - 6s - loss: 5.2347e-05 - accuracy: 0.5519 - val_loss: 0.0066 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 85/100\n72/72 - 6s - loss: 1.4413e-05 - accuracy: 0.5619 - val_loss: 0.0066 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 86/100\n72/72 - 6s - loss: 2.0543e-05 - accuracy: 0.5653 - val_loss: 0.0052 - val_accuracy: 0.5325 - 6s/epoch - 87ms/step\nEpoch 87/100\n72/72 - 6s - loss: 3.9799e-05 - accuracy: 0.5628 - val_loss: 0.0064 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 88/100\n72/72 - 6s - loss: 1.1378e-05 - accuracy: 0.5644 - val_loss: 0.0064 - val_accuracy: 0.5325 - 6s/epoch - 87ms/step\nEpoch 89/100\n72/72 - 6s - loss: 3.9332e-05 - accuracy: 0.5633 - val_loss: 0.0083 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 90/100\n72/72 - 6s - loss: 3.4885e-05 - accuracy: 0.5614 - val_loss: 0.0068 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 91/100\n72/72 - 6s - loss: 5.7805e-05 - accuracy: 0.5636 - val_loss: 0.0054 - val_accuracy: 0.5075 - 6s/epoch - 87ms/step\nEpoch 92/100\n72/72 - 6s - loss: 7.1954e-05 - accuracy: 0.5542 - val_loss: 0.0064 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 93/100\n72/72 - 6s - loss: 7.9846e-05 - accuracy: 0.5569 - val_loss: 0.0094 - val_accuracy: 0.5175 - 6s/epoch - 87ms/step\nEpoch 94/100\n72/72 - 6s - loss: 3.5646e-05 - accuracy: 0.5544 - val_loss: 0.0092 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 95/100\n72/72 - 6s - loss: 2.3684e-05 - accuracy: 0.5503 - val_loss: 0.0078 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 96/100\n72/72 - 6s - loss: 4.6218e-05 - accuracy: 0.5531 - val_loss: 0.0083 - val_accuracy: 0.5325 - 6s/epoch - 88ms/step\nEpoch 97/100\n72/72 - 6s - loss: 1.1896e-05 - accuracy: 0.5561 - val_loss: 0.0079 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 98/100\n72/72 - 6s - loss: 1.6867e-05 - accuracy: 0.5606 - val_loss: 0.0078 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 99/100\n72/72 - 6s - loss: 2.6434e-05 - accuracy: 0.5569 - val_loss: 0.0070 - val_accuracy: 0.5300 - 6s/epoch - 86ms/step\nEpoch 100/100\n72/72 - 6s - loss: 9.2312e-05 - accuracy: 0.5547 - val_loss: 0.0104 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 1/100\n72/72 - 6s - loss: 1.5857e-04 - accuracy: 0.5478 - val_loss: 0.0158 - val_accuracy: 0.6075 - 6s/epoch - 88ms/step\nEpoch 2/100\n72/72 - 6s - loss: 5.8922e-05 - accuracy: 0.5481 - val_loss: 0.0097 - val_accuracy: 0.5750 - 6s/epoch - 87ms/step\nEpoch 3/100\n72/72 - 6s - loss: 4.3686e-05 - accuracy: 0.5461 - val_loss: 0.0096 - val_accuracy: 0.5775 - 6s/epoch - 87ms/step\nEpoch 4/100\n72/72 - 6s - loss: 7.4090e-05 - accuracy: 0.5453 - val_loss: 0.0093 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 5/100\n72/72 - 6s - loss: 1.1317e-04 - accuracy: 0.5483 - val_loss: 0.0075 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 6/100\n72/72 - 6s - loss: 4.6856e-05 - accuracy: 0.5375 - val_loss: 0.0057 - val_accuracy: 0.5725 - 6s/epoch - 85ms/step\nEpoch 7/100\n72/72 - 6s - loss: 9.0332e-05 - accuracy: 0.5356 - val_loss: 0.0029 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 8/100\n72/72 - 6s - loss: 2.4645e-05 - accuracy: 0.5386 - val_loss: 0.0050 - val_accuracy: 0.5700 - 6s/epoch - 87ms/step\nEpoch 9/100\n72/72 - 6s - loss: 4.1661e-05 - accuracy: 0.5367 - val_loss: 0.0020 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 10/100\n72/72 - 6s - loss: 3.8362e-05 - accuracy: 0.5486 - val_loss: 0.0039 - val_accuracy: 0.5900 - 6s/epoch - 86ms/step\nEpoch 11/100\n72/72 - 6s - loss: 4.0646e-05 - accuracy: 0.5506 - val_loss: 0.0029 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 12/100\n72/72 - 6s - loss: 3.2609e-05 - accuracy: 0.5464 - val_loss: 0.0019 - val_accuracy: 0.5825 - 6s/epoch - 86ms/step\nEpoch 13/100\n72/72 - 6s - loss: 9.7603e-05 - accuracy: 0.5483 - val_loss: 0.0025 - val_accuracy: 0.5925 - 6s/epoch - 87ms/step\nEpoch 14/100\n72/72 - 6s - loss: 5.9271e-05 - accuracy: 0.5514 - val_loss: 0.0028 - val_accuracy: 0.5850 - 6s/epoch - 85ms/step\nEpoch 15/100\n72/72 - 6s - loss: 1.1265e-04 - accuracy: 0.5494 - val_loss: 0.0029 - val_accuracy: 0.5825 - 6s/epoch - 87ms/step\nEpoch 16/100\n72/72 - 6s - loss: 4.0202e-05 - accuracy: 0.5575 - val_loss: 0.0045 - val_accuracy: 0.6150 - 6s/epoch - 87ms/step\nEpoch 17/100\n72/72 - 6s - loss: 3.5317e-05 - accuracy: 0.5625 - val_loss: 0.0042 - val_accuracy: 0.6025 - 6s/epoch - 87ms/step\nEpoch 18/100\n72/72 - 6s - loss: 2.5249e-05 - accuracy: 0.5500 - val_loss: 0.0057 - val_accuracy: 0.5900 - 6s/epoch - 87ms/step\nEpoch 19/100\n72/72 - 6s - loss: 1.1996e-05 - accuracy: 0.5492 - val_loss: 0.0053 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 20/100\n72/72 - 6s - loss: 3.1862e-05 - accuracy: 0.5542 - val_loss: 0.0037 - val_accuracy: 0.5975 - 6s/epoch - 87ms/step\nEpoch 21/100\n72/72 - 6s - loss: 7.0774e-05 - accuracy: 0.5531 - val_loss: 0.0073 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 22/100\n72/72 - 6s - loss: 9.7794e-05 - accuracy: 0.5442 - val_loss: 2.4212e-05 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 23/100\n72/72 - 6s - loss: 7.6483e-05 - accuracy: 0.5389 - val_loss: 0.0052 - val_accuracy: 0.5850 - 6s/epoch - 88ms/step\nEpoch 24/100\n72/72 - 6s - loss: 0.0011 - accuracy: 0.5533 - val_loss: 6.0406e-05 - val_accuracy: 0.6150 - 6s/epoch - 86ms/step\nEpoch 25/100\n72/72 - 6s - loss: 1.7296e-04 - accuracy: 0.5611 - val_loss: 4.1805e-04 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 26/100\n72/72 - 6s - loss: 1.2552e-04 - accuracy: 0.5558 - val_loss: 5.8554e-04 - val_accuracy: 0.6025 - 6s/epoch - 86ms/step\nEpoch 27/100\n72/72 - 6s - loss: 9.3914e-05 - accuracy: 0.5439 - val_loss: 1.0868e-05 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 28/100\n72/72 - 6s - loss: 6.4289e-05 - accuracy: 0.5378 - val_loss: 3.4109e-05 - val_accuracy: 0.6025 - 6s/epoch - 87ms/step\nEpoch 29/100\n72/72 - 6s - loss: 6.4146e-05 - accuracy: 0.5536 - val_loss: 0.0014 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 30/100\n72/72 - 6s - loss: 7.2322e-05 - accuracy: 0.5503 - val_loss: 0.0019 - val_accuracy: 0.6025 - 6s/epoch - 85ms/step\nEpoch 31/100\n72/72 - 6s - loss: 7.6335e-04 - accuracy: 0.5544 - val_loss: 2.1909e-04 - val_accuracy: 0.6125 - 6s/epoch - 87ms/step\nEpoch 32/100\n72/72 - 6s - loss: 1.0064e-04 - accuracy: 0.5558 - val_loss: 2.9175e-04 - val_accuracy: 0.6150 - 6s/epoch - 85ms/step\nEpoch 33/100\n72/72 - 6s - loss: 6.7718e-05 - accuracy: 0.5475 - val_loss: 3.2659e-06 - val_accuracy: 0.5925 - 6s/epoch - 86ms/step\nEpoch 34/100\n72/72 - 6s - loss: 7.2137e-05 - accuracy: 0.5456 - val_loss: 4.2011e-04 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 35/100\n72/72 - 6s - loss: 3.8505e-05 - accuracy: 0.5458 - val_loss: 1.8049e-04 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 36/100\n72/72 - 6s - loss: 1.2852e-04 - accuracy: 0.5442 - val_loss: 0.0011 - val_accuracy: 0.5925 - 6s/epoch - 86ms/step\nEpoch 37/100\n72/72 - 6s - loss: 1.0986e-04 - accuracy: 0.5444 - val_loss: 0.0028 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 38/100\n72/72 - 6s - loss: 2.1254e-04 - accuracy: 0.5417 - val_loss: 0.0015 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 39/100\n72/72 - 6s - loss: 3.0878e-04 - accuracy: 0.5336 - val_loss: 8.4855e-04 - val_accuracy: 0.5725 - 6s/epoch - 85ms/step\nEpoch 40/100\n72/72 - 6s - loss: 6.3594e-05 - accuracy: 0.5369 - val_loss: 0.0016 - val_accuracy: 0.5850 - 6s/epoch - 85ms/step\nEpoch 41/100\n72/72 - 6s - loss: 0.0011 - accuracy: 0.5275 - val_loss: 0.0888 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 42/100\n72/72 - 6s - loss: 2.0456e-04 - accuracy: 0.5367 - val_loss: 0.0044 - val_accuracy: 0.5850 - 6s/epoch - 87ms/step\nEpoch 43/100\n72/72 - 6s - loss: 5.0161e-04 - accuracy: 0.5464 - val_loss: 0.0018 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 44/100\n72/72 - 6s - loss: 2.2406e-04 - accuracy: 0.5500 - val_loss: 8.6743e-04 - val_accuracy: 0.5800 - 6s/epoch - 86ms/step\nEpoch 45/100\n72/72 - 6s - loss: 2.0573e-04 - accuracy: 0.5453 - val_loss: 4.0479e-04 - val_accuracy: 0.5825 - 6s/epoch - 87ms/step\nEpoch 46/100\n72/72 - 6s - loss: 2.3608e-04 - accuracy: 0.5400 - val_loss: 4.0405e-05 - val_accuracy: 0.5675 - 6s/epoch - 85ms/step\nEpoch 47/100\n72/72 - 6s - loss: 3.7670e-04 - accuracy: 0.5397 - val_loss: 1.4691e-04 - val_accuracy: 0.6025 - 6s/epoch - 87ms/step\nEpoch 48/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5414 - val_loss: 1.6827e-05 - val_accuracy: 0.6050 - 6s/epoch - 86ms/step\nEpoch 49/100\n72/72 - 6s - loss: 5.3787e-04 - accuracy: 0.5433 - val_loss: 1.2095e-04 - val_accuracy: 0.6050 - 6s/epoch - 86ms/step\nEpoch 50/100\n72/72 - 6s - loss: 2.6465e-04 - accuracy: 0.5378 - val_loss: 1.3323e-06 - val_accuracy: 0.5750 - 6s/epoch - 86ms/step\nEpoch 51/100\n72/72 - 6s - loss: 5.9296e-05 - accuracy: 0.5350 - val_loss: 7.5213e-07 - val_accuracy: 0.5950 - 6s/epoch - 86ms/step\nEpoch 52/100\n72/72 - 6s - loss: 1.2511e-04 - accuracy: 0.5414 - val_loss: 3.4514e-07 - val_accuracy: 0.5975 - 6s/epoch - 86ms/step\nEpoch 53/100\n72/72 - 6s - loss: 2.4893e-04 - accuracy: 0.5442 - val_loss: 1.2815e-06 - val_accuracy: 0.5925 - 6s/epoch - 87ms/step\nEpoch 54/100\n72/72 - 6s - loss: 3.4628e-04 - accuracy: 0.5342 - val_loss: 9.5391e-07 - val_accuracy: 0.5800 - 6s/epoch - 88ms/step\nEpoch 55/100\n72/72 - 6s - loss: 3.7598e-04 - accuracy: 0.5414 - val_loss: 9.0950e-04 - val_accuracy: 0.5950 - 6s/epoch - 86ms/step\nEpoch 56/100\n72/72 - 6s - loss: 2.8274e-04 - accuracy: 0.5406 - val_loss: 2.4787e-05 - val_accuracy: 0.5775 - 6s/epoch - 85ms/step\nEpoch 57/100\n72/72 - 6s - loss: 2.6778e-04 - accuracy: 0.5383 - val_loss: 2.0743e-06 - val_accuracy: 0.6000 - 6s/epoch - 85ms/step\nEpoch 58/100\n72/72 - 6s - loss: 1.2029e-04 - accuracy: 0.5417 - val_loss: 2.1746e-06 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 59/100\n72/72 - 6s - loss: 2.1994e-04 - accuracy: 0.5439 - val_loss: 2.9070e-06 - val_accuracy: 0.5800 - 6s/epoch - 87ms/step\nEpoch 60/100\n72/72 - 6s - loss: 5.5866e-05 - accuracy: 0.5469 - val_loss: 1.7249e-06 - val_accuracy: 0.6075 - 6s/epoch - 86ms/step\nEpoch 61/100\n72/72 - 6s - loss: 8.8959e-05 - accuracy: 0.5492 - val_loss: 8.4230e-07 - val_accuracy: 0.6050 - 6s/epoch - 86ms/step\nEpoch 62/100\n72/72 - 6s - loss: 1.1642e-04 - accuracy: 0.5506 - val_loss: 1.9082e-06 - val_accuracy: 0.5825 - 6s/epoch - 86ms/step\nEpoch 63/100\n72/72 - 6s - loss: 3.0397e-04 - accuracy: 0.5489 - val_loss: 5.8352e-04 - val_accuracy: 0.5925 - 6s/epoch - 86ms/step\nEpoch 64/100\n72/72 - 6s - loss: 2.2687e-04 - accuracy: 0.5472 - val_loss: 5.2838e-04 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 65/100\n72/72 - 6s - loss: 6.4217e-04 - accuracy: 0.5447 - val_loss: 4.0959e-04 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 66/100\n72/72 - 6s - loss: 3.6492e-04 - accuracy: 0.5517 - val_loss: 0.0023 - val_accuracy: 0.6150 - 6s/epoch - 87ms/step\nEpoch 67/100\n72/72 - 6s - loss: 1.4331e-04 - accuracy: 0.5492 - val_loss: 0.0038 - val_accuracy: 0.6050 - 6s/epoch - 85ms/step\nEpoch 68/100\n72/72 - 6s - loss: 1.9732e-04 - accuracy: 0.5456 - val_loss: 0.0062 - val_accuracy: 0.5975 - 6s/epoch - 87ms/step\nEpoch 69/100\n72/72 - 6s - loss: 2.0436e-04 - accuracy: 0.5414 - val_loss: 0.0034 - val_accuracy: 0.5900 - 6s/epoch - 86ms/step\nEpoch 70/100\n72/72 - 6s - loss: 0.0017 - accuracy: 0.5567 - val_loss: 0.0012 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 71/100\n72/72 - 6s - loss: 4.1313e-04 - accuracy: 0.5419 - val_loss: 0.0019 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 72/100\n72/72 - 6s - loss: 4.5660e-04 - accuracy: 0.5514 - val_loss: 3.7592e-04 - val_accuracy: 0.6500 - 6s/epoch - 87ms/step\nEpoch 73/100\n72/72 - 6s - loss: 7.5865e-04 - accuracy: 0.5514 - val_loss: 7.7182e-05 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 74/100\n72/72 - 6s - loss: 4.3767e-04 - accuracy: 0.5478 - val_loss: 8.3562e-05 - val_accuracy: 0.6050 - 6s/epoch - 87ms/step\nEpoch 75/100\n72/72 - 6s - loss: 1.6102e-04 - accuracy: 0.5539 - val_loss: 4.7719e-04 - val_accuracy: 0.6150 - 6s/epoch - 87ms/step\nEpoch 76/100\n72/72 - 6s - loss: 1.3287e-04 - accuracy: 0.5542 - val_loss: 5.4297e-05 - val_accuracy: 0.6075 - 6s/epoch - 87ms/step\nEpoch 77/100\n72/72 - 6s - loss: 9.8241e-05 - accuracy: 0.5553 - val_loss: 9.6532e-05 - val_accuracy: 0.6200 - 6s/epoch - 87ms/step\nEpoch 78/100\n72/72 - 6s - loss: 1.8714e-04 - accuracy: 0.5614 - val_loss: 4.8229e-04 - val_accuracy: 0.6000 - 6s/epoch - 87ms/step\nEpoch 79/100\n72/72 - 6s - loss: 1.4946e-04 - accuracy: 0.5592 - val_loss: 5.7890e-04 - val_accuracy: 0.6000 - 6s/epoch - 88ms/step\nEpoch 80/100\n72/72 - 6s - loss: 1.5677e-04 - accuracy: 0.5636 - val_loss: 0.0017 - val_accuracy: 0.6200 - 6s/epoch - 86ms/step\nEpoch 81/100\n72/72 - 6s - loss: 1.4110e-04 - accuracy: 0.5628 - val_loss: 3.9640e-05 - val_accuracy: 0.6075 - 6s/epoch - 86ms/step\nEpoch 82/100\n72/72 - 6s - loss: 1.4629e-04 - accuracy: 0.5561 - val_loss: 5.5952e-04 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 83/100\n72/72 - 6s - loss: 7.4730e-05 - accuracy: 0.5556 - val_loss: 6.7449e-04 - val_accuracy: 0.6125 - 6s/epoch - 86ms/step\nEpoch 84/100\n72/72 - 6s - loss: 2.3025e-04 - accuracy: 0.5481 - val_loss: 1.7068e-05 - val_accuracy: 0.6000 - 6s/epoch - 86ms/step\nEpoch 85/100\n72/72 - 6s - loss: 1.8790e-04 - accuracy: 0.5603 - val_loss: 5.2762e-05 - val_accuracy: 0.6425 - 6s/epoch - 85ms/step\nEpoch 86/100\n72/72 - 6s - loss: 1.7174e-04 - accuracy: 0.5736 - val_loss: 9.2688e-04 - val_accuracy: 0.6075 - 6s/epoch - 87ms/step\nEpoch 87/100\n72/72 - 6s - loss: 2.3517e-04 - accuracy: 0.5589 - val_loss: 2.0353e-06 - val_accuracy: 0.6075 - 6s/epoch - 87ms/step\nEpoch 88/100\n72/72 - 6s - loss: 2.0991e-04 - accuracy: 0.5542 - val_loss: 5.3742e-05 - val_accuracy: 0.5900 - 6s/epoch - 85ms/step\nEpoch 89/100\n72/72 - 6s - loss: 7.7270e-05 - accuracy: 0.5533 - val_loss: 1.6568e-06 - val_accuracy: 0.6075 - 6s/epoch - 86ms/step\nEpoch 90/100\n72/72 - 6s - loss: 1.0270e-04 - accuracy: 0.5525 - val_loss: 2.5632e-06 - val_accuracy: 0.6075 - 6s/epoch - 86ms/step\nEpoch 91/100\n72/72 - 6s - loss: 1.1215e-04 - accuracy: 0.5517 - val_loss: 3.7518e-06 - val_accuracy: 0.6025 - 6s/epoch - 87ms/step\nEpoch 92/100\n72/72 - 6s - loss: 2.1825e-04 - accuracy: 0.5458 - val_loss: 3.0256e-05 - val_accuracy: 0.6050 - 6s/epoch - 87ms/step\nEpoch 93/100\n72/72 - 6s - loss: 1.2750e-04 - accuracy: 0.5444 - val_loss: 1.0346e-04 - val_accuracy: 0.6100 - 6s/epoch - 86ms/step\nEpoch 94/100\n72/72 - 6s - loss: 3.4538e-04 - accuracy: 0.5486 - val_loss: 1.5867e-05 - val_accuracy: 0.6050 - 6s/epoch - 86ms/step\nEpoch 95/100\n72/72 - 6s - loss: 2.5528e-04 - accuracy: 0.5525 - val_loss: 8.1520e-05 - val_accuracy: 0.6100 - 6s/epoch - 86ms/step\nEpoch 96/100\n72/72 - 6s - loss: 1.6875e-04 - accuracy: 0.5528 - val_loss: 4.5770e-05 - val_accuracy: 0.6100 - 6s/epoch - 87ms/step\nEpoch 97/100\n72/72 - 6s - loss: 3.5876e-04 - accuracy: 0.5419 - val_loss: 1.9720e-04 - val_accuracy: 0.5875 - 6s/epoch - 87ms/step\nEpoch 98/100\n72/72 - 6s - loss: 2.3074e-04 - accuracy: 0.5464 - val_loss: 8.0106e-06 - val_accuracy: 0.6200 - 6s/epoch - 87ms/step\nEpoch 99/100\n72/72 - 6s - loss: 6.8301e-05 - accuracy: 0.5497 - val_loss: 5.9103e-06 - val_accuracy: 0.6050 - 6s/epoch - 86ms/step\nEpoch 100/100\n72/72 - 6s - loss: 1.3367e-04 - accuracy: 0.5489 - val_loss: 1.5750e-05 - val_accuracy: 0.5925 - 6s/epoch - 86ms/step\nEpoch 1/100\n72/72 - 6s - loss: 1.0905e-04 - accuracy: 0.5597 - val_loss: 7.6301e-05 - val_accuracy: 0.5250 - 6s/epoch - 88ms/step\nEpoch 2/100\n72/72 - 6s - loss: 4.2909e-04 - accuracy: 0.5583 - val_loss: 2.6867e-06 - val_accuracy: 0.5250 - 6s/epoch - 86ms/step\nEpoch 3/100\n72/72 - 6s - loss: 3.1194e-04 - accuracy: 0.5603 - val_loss: 5.7709e-06 - val_accuracy: 0.5225 - 6s/epoch - 88ms/step\nEpoch 4/100\n72/72 - 6s - loss: 3.6880e-04 - accuracy: 0.5608 - val_loss: 5.5092e-06 - val_accuracy: 0.5225 - 6s/epoch - 88ms/step\nEpoch 5/100\n72/72 - 6s - loss: 5.4682e-05 - accuracy: 0.5622 - val_loss: 8.5289e-07 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 6/100\n72/72 - 6s - loss: 5.4040e-05 - accuracy: 0.5606 - val_loss: 1.5126e-06 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 7/100\n72/72 - 6s - loss: 4.5886e-04 - accuracy: 0.5611 - val_loss: 2.3678e-04 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 8/100\n72/72 - 6s - loss: 7.1610e-04 - accuracy: 0.5617 - val_loss: 1.9868e-04 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 9/100\n72/72 - 6s - loss: 2.5897e-04 - accuracy: 0.5614 - val_loss: 2.1406e-05 - val_accuracy: 0.5350 - 6s/epoch - 88ms/step\nEpoch 10/100\n72/72 - 6s - loss: 8.0753e-04 - accuracy: 0.5581 - val_loss: 4.3389e-05 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 11/100\n72/72 - 6s - loss: 6.3732e-04 - accuracy: 0.5628 - val_loss: 7.5996e-05 - val_accuracy: 0.5325 - 6s/epoch - 87ms/step\nEpoch 12/100\n72/72 - 6s - loss: 1.8873e-04 - accuracy: 0.5603 - val_loss: 1.1798e-05 - val_accuracy: 0.5175 - 6s/epoch - 87ms/step\nEpoch 13/100\n72/72 - 6s - loss: 1.3860e-04 - accuracy: 0.5511 - val_loss: 1.9945e-06 - val_accuracy: 0.5400 - 6s/epoch - 86ms/step\nEpoch 14/100\n72/72 - 6s - loss: 8.2206e-05 - accuracy: 0.5531 - val_loss: 2.7032e-06 - val_accuracy: 0.5275 - 6s/epoch - 88ms/step\nEpoch 15/100\n72/72 - 6s - loss: 5.9136e-05 - accuracy: 0.5556 - val_loss: 2.0436e-06 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 16/100\n72/72 - 6s - loss: 5.6942e-05 - accuracy: 0.5569 - val_loss: 4.3974e-06 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 17/100\n72/72 - 6s - loss: 3.6137e-04 - accuracy: 0.5547 - val_loss: 1.7935e-05 - val_accuracy: 0.5000 - 6s/epoch - 88ms/step\nEpoch 18/100\n72/72 - 6s - loss: 5.7766e-05 - accuracy: 0.5561 - val_loss: 3.1626e-07 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 19/100\n72/72 - 6s - loss: 5.5715e-05 - accuracy: 0.5547 - val_loss: 1.2618e-06 - val_accuracy: 0.5275 - 6s/epoch - 89ms/step\nEpoch 20/100\n72/72 - 6s - loss: 4.9073e-05 - accuracy: 0.5658 - val_loss: 3.0512e-07 - val_accuracy: 0.5300 - 6s/epoch - 88ms/step\nEpoch 21/100\n72/72 - 6s - loss: 2.7740e-05 - accuracy: 0.5697 - val_loss: 4.9047e-07 - val_accuracy: 0.5300 - 6s/epoch - 86ms/step\nEpoch 22/100\n72/72 - 6s - loss: 6.8075e-05 - accuracy: 0.5636 - val_loss: 2.6310e-07 - val_accuracy: 0.5150 - 6s/epoch - 86ms/step\nEpoch 23/100\n72/72 - 6s - loss: 1.3085e-04 - accuracy: 0.5644 - val_loss: 3.9256e-07 - val_accuracy: 0.5150 - 6s/epoch - 86ms/step\nEpoch 24/100\n72/72 - 6s - loss: 5.3382e-04 - accuracy: 0.5775 - val_loss: 1.7345e-05 - val_accuracy: 0.5525 - 6s/epoch - 88ms/step\nEpoch 25/100\n72/72 - 6s - loss: 4.9792e-05 - accuracy: 0.5692 - val_loss: 3.9217e-06 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 26/100\n72/72 - 6s - loss: 3.4930e-05 - accuracy: 0.5636 - val_loss: 3.8473e-06 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 27/100\n72/72 - 6s - loss: 2.1773e-04 - accuracy: 0.5617 - val_loss: 9.5772e-06 - val_accuracy: 0.5050 - 6s/epoch - 86ms/step\nEpoch 28/100\n72/72 - 6s - loss: 2.8623e-04 - accuracy: 0.5542 - val_loss: 1.1268e-06 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 29/100\n72/72 - 6s - loss: 3.7728e-04 - accuracy: 0.5625 - val_loss: 5.6180e-04 - val_accuracy: 0.5700 - 6s/epoch - 89ms/step\nEpoch 30/100\n72/72 - 6s - loss: 4.9160e-04 - accuracy: 0.5675 - val_loss: 1.5202e-05 - val_accuracy: 0.5050 - 6s/epoch - 87ms/step\nEpoch 31/100\n72/72 - 6s - loss: 1.4706e-04 - accuracy: 0.5600 - val_loss: 2.7304e-06 - val_accuracy: 0.5175 - 6s/epoch - 86ms/step\nEpoch 32/100\n72/72 - 6s - loss: 9.8572e-05 - accuracy: 0.5594 - val_loss: 4.0736e-05 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 33/100\n72/72 - 6s - loss: 5.2040e-05 - accuracy: 0.5589 - val_loss: 1.4689e-06 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 34/100\n72/72 - 6s - loss: 1.1726e-04 - accuracy: 0.5556 - val_loss: 4.4187e-05 - val_accuracy: 0.5100 - 6s/epoch - 89ms/step\nEpoch 35/100\n72/72 - 6s - loss: 7.5616e-05 - accuracy: 0.5578 - val_loss: 8.1264e-07 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 36/100\n72/72 - 6s - loss: 4.4962e-04 - accuracy: 0.5567 - val_loss: 6.2551e-04 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 37/100\n72/72 - 6s - loss: 2.8980e-04 - accuracy: 0.5625 - val_loss: 1.1726e-04 - val_accuracy: 0.5375 - 6s/epoch - 87ms/step\nEpoch 38/100\n72/72 - 6s - loss: 1.6692e-04 - accuracy: 0.5644 - val_loss: 1.0983e-05 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 39/100\n72/72 - 6s - loss: 2.3685e-04 - accuracy: 0.5778 - val_loss: 0.0026 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 40/100\n72/72 - 6s - loss: 1.3190e-04 - accuracy: 0.5731 - val_loss: 1.2949e-05 - val_accuracy: 0.5375 - 6s/epoch - 88ms/step\nEpoch 41/100\n72/72 - 6s - loss: 1.0695e-04 - accuracy: 0.5747 - val_loss: 2.3566e-05 - val_accuracy: 0.5575 - 6s/epoch - 88ms/step\nEpoch 42/100\n72/72 - 6s - loss: 0.0012 - accuracy: 0.5672 - val_loss: 1.7831e-05 - val_accuracy: 0.5175 - 6s/epoch - 86ms/step\nEpoch 43/100\n72/72 - 6s - loss: 3.8016e-04 - accuracy: 0.5742 - val_loss: 1.0334e-04 - val_accuracy: 0.5150 - 6s/epoch - 87ms/step\nEpoch 44/100\n72/72 - 6s - loss: 1.9373e-04 - accuracy: 0.5675 - val_loss: 3.8026e-04 - val_accuracy: 0.5500 - 6s/epoch - 90ms/step\nEpoch 45/100\n72/72 - 6s - loss: 1.9806e-04 - accuracy: 0.5703 - val_loss: 3.4942e-05 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 46/100\n72/72 - 6s - loss: 2.5844e-04 - accuracy: 0.5803 - val_loss: 1.3300e-05 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 47/100\n72/72 - 6s - loss: 1.0588e-04 - accuracy: 0.5683 - val_loss: 6.0348e-06 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 48/100\n72/72 - 6s - loss: 2.2492e-04 - accuracy: 0.5733 - val_loss: 1.4039e-04 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 49/100\n72/72 - 6s - loss: 1.2594e-04 - accuracy: 0.5700 - val_loss: 8.0199e-05 - val_accuracy: 0.5450 - 6s/epoch - 89ms/step\nEpoch 50/100\n72/72 - 6s - loss: 3.3190e-04 - accuracy: 0.5686 - val_loss: 1.6897e-05 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 51/100\n72/72 - 6s - loss: 1.2895e-04 - accuracy: 0.5683 - val_loss: 6.0991e-06 - val_accuracy: 0.5375 - 6s/epoch - 88ms/step\nEpoch 52/100\n72/72 - 6s - loss: 2.7384e-04 - accuracy: 0.5644 - val_loss: 3.0426e-06 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 53/100\n72/72 - 6s - loss: 5.2352e-04 - accuracy: 0.5600 - val_loss: 5.1425e-04 - val_accuracy: 0.5225 - 6s/epoch - 87ms/step\nEpoch 54/100\n72/72 - 6s - loss: 2.5721e-04 - accuracy: 0.5611 - val_loss: 2.4382e-04 - val_accuracy: 0.5350 - 6s/epoch - 88ms/step\nEpoch 55/100\n72/72 - 6s - loss: 4.0047e-04 - accuracy: 0.5531 - val_loss: 1.0780e-04 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 56/100\n72/72 - 6s - loss: 2.8120e-04 - accuracy: 0.5639 - val_loss: 9.8033e-05 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 57/100\n72/72 - 6s - loss: 2.1612e-04 - accuracy: 0.5628 - val_loss: 4.6908e-06 - val_accuracy: 0.5525 - 6s/epoch - 88ms/step\nEpoch 58/100\n72/72 - 6s - loss: 1.7885e-04 - accuracy: 0.5642 - val_loss: 2.2649e-05 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 59/100\n72/72 - 6s - loss: 4.2367e-05 - accuracy: 0.5614 - val_loss: 5.6144e-06 - val_accuracy: 0.5400 - 6s/epoch - 89ms/step\nEpoch 60/100\n72/72 - 6s - loss: 3.9115e-05 - accuracy: 0.5639 - val_loss: 8.9694e-06 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 61/100\n72/72 - 6s - loss: 3.7715e-05 - accuracy: 0.5697 - val_loss: 2.6938e-06 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 62/100\n72/72 - 6s - loss: 2.6688e-05 - accuracy: 0.5600 - val_loss: 2.4739e-06 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 63/100\n72/72 - 6s - loss: 3.9438e-05 - accuracy: 0.5581 - val_loss: 3.1635e-06 - val_accuracy: 0.5225 - 6s/epoch - 87ms/step\nEpoch 64/100\n72/72 - 6s - loss: 6.6880e-05 - accuracy: 0.5578 - val_loss: 4.1810e-06 - val_accuracy: 0.5325 - 6s/epoch - 87ms/step\nEpoch 65/100\n72/72 - 6s - loss: 2.4587e-05 - accuracy: 0.5722 - val_loss: 3.7542e-06 - val_accuracy: 0.5325 - 6s/epoch - 87ms/step\nEpoch 66/100\n72/72 - 6s - loss: 3.5491e-05 - accuracy: 0.5656 - val_loss: 2.6497e-06 - val_accuracy: 0.5375 - 6s/epoch - 88ms/step\nEpoch 67/100\n72/72 - 6s - loss: 1.9987e-04 - accuracy: 0.5683 - val_loss: 1.7405e-04 - val_accuracy: 0.5100 - 6s/epoch - 87ms/step\nEpoch 68/100\n72/72 - 6s - loss: 3.0152e-04 - accuracy: 0.5514 - val_loss: 2.3688e-04 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 69/100\n72/72 - 6s - loss: 2.9502e-04 - accuracy: 0.5625 - val_loss: 2.3230e-05 - val_accuracy: 0.5325 - 6s/epoch - 88ms/step\nEpoch 70/100\n72/72 - 6s - loss: 3.0453e-04 - accuracy: 0.5594 - val_loss: 3.0031e-05 - val_accuracy: 0.5225 - 6s/epoch - 89ms/step\nEpoch 71/100\n72/72 - 6s - loss: 4.5127e-04 - accuracy: 0.5528 - val_loss: 5.0586e-05 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 72/100\n72/72 - 6s - loss: 1.8414e-04 - accuracy: 0.5625 - val_loss: 2.8149e-05 - val_accuracy: 0.5175 - 6s/epoch - 87ms/step\nEpoch 73/100\n72/72 - 6s - loss: 2.0180e-04 - accuracy: 0.5631 - val_loss: 7.1423e-05 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 74/100\n72/72 - 6s - loss: 1.3397e-04 - accuracy: 0.5644 - val_loss: 0.0020 - val_accuracy: 0.5350 - 6s/epoch - 87ms/step\nEpoch 75/100\n72/72 - 6s - loss: 1.1137e-04 - accuracy: 0.5717 - val_loss: 1.9015e-05 - val_accuracy: 0.5275 - 6s/epoch - 89ms/step\nEpoch 76/100\n72/72 - 6s - loss: 3.8979e-05 - accuracy: 0.5706 - val_loss: 1.1599e-05 - val_accuracy: 0.5250 - 6s/epoch - 88ms/step\nEpoch 77/100\n72/72 - 6s - loss: 4.6431e-05 - accuracy: 0.5653 - val_loss: 8.3611e-06 - val_accuracy: 0.5300 - 6s/epoch - 87ms/step\nEpoch 78/100\n72/72 - 6s - loss: 5.3380e-05 - accuracy: 0.5631 - val_loss: 3.3490e-05 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 79/100\n72/72 - 6s - loss: 4.4821e-05 - accuracy: 0.5611 - val_loss: 2.3055e-05 - val_accuracy: 0.5250 - 6s/epoch - 88ms/step\nEpoch 80/100\n72/72 - 6s - loss: 1.6446e-04 - accuracy: 0.5628 - val_loss: 9.1107e-06 - val_accuracy: 0.5150 - 6s/epoch - 88ms/step\nEpoch 81/100\n72/72 - 6s - loss: 1.2027e-04 - accuracy: 0.5664 - val_loss: 3.5822e-05 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 82/100\n72/72 - 6s - loss: 5.4378e-04 - accuracy: 0.5647 - val_loss: 1.1830e-04 - val_accuracy: 0.5175 - 6s/epoch - 87ms/step\nEpoch 83/100\n72/72 - 6s - loss: 2.7122e-04 - accuracy: 0.5647 - val_loss: 5.4235e-04 - val_accuracy: 0.5100 - 6s/epoch - 87ms/step\nEpoch 84/100\n72/72 - 6s - loss: 1.3274e-04 - accuracy: 0.5703 - val_loss: 3.3035e-05 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 85/100\n72/72 - 6s - loss: 1.7733e-04 - accuracy: 0.5756 - val_loss: 1.9032e-05 - val_accuracy: 0.5250 - 6s/epoch - 88ms/step\nEpoch 86/100\n72/72 - 6s - loss: 2.1530e-04 - accuracy: 0.5811 - val_loss: 1.1075e-04 - val_accuracy: 0.5400 - 6s/epoch - 88ms/step\nEpoch 87/100\n72/72 - 6s - loss: 7.2415e-05 - accuracy: 0.5731 - val_loss: 2.1917e-05 - val_accuracy: 0.5300 - 6s/epoch - 88ms/step\nEpoch 88/100\n72/72 - 6s - loss: 9.2353e-05 - accuracy: 0.5697 - val_loss: 1.3912e-05 - val_accuracy: 0.5300 - 6s/epoch - 86ms/step\nEpoch 89/100\n72/72 - 6s - loss: 8.2556e-05 - accuracy: 0.5664 - val_loss: 9.1626e-05 - val_accuracy: 0.5200 - 6s/epoch - 86ms/step\nEpoch 90/100\n72/72 - 6s - loss: 1.5682e-04 - accuracy: 0.5636 - val_loss: 5.3565e-05 - val_accuracy: 0.5250 - 6s/epoch - 88ms/step\nEpoch 91/100\n72/72 - 6s - loss: 3.2325e-05 - accuracy: 0.5661 - val_loss: 4.6384e-05 - val_accuracy: 0.5225 - 6s/epoch - 86ms/step\nEpoch 92/100\n72/72 - 6s - loss: 8.8652e-05 - accuracy: 0.5603 - val_loss: 1.6374e-04 - val_accuracy: 0.5400 - 6s/epoch - 88ms/step\nEpoch 93/100\n72/72 - 6s - loss: 6.8748e-05 - accuracy: 0.5692 - val_loss: 3.1929e-05 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 94/100\n72/72 - 6s - loss: 2.0541e-05 - accuracy: 0.5642 - val_loss: 1.5261e-05 - val_accuracy: 0.5250 - 6s/epoch - 88ms/step\nEpoch 95/100\n72/72 - 6s - loss: 2.1157e-05 - accuracy: 0.5603 - val_loss: 1.1253e-05 - val_accuracy: 0.5225 - 6s/epoch - 88ms/step\nEpoch 96/100\n72/72 - 6s - loss: 2.3166e-05 - accuracy: 0.5658 - val_loss: 1.2013e-05 - val_accuracy: 0.5250 - 6s/epoch - 87ms/step\nEpoch 97/100\n72/72 - 6s - loss: 2.8905e-05 - accuracy: 0.5644 - val_loss: 1.0800e-05 - val_accuracy: 0.5275 - 6s/epoch - 87ms/step\nEpoch 98/100\n72/72 - 6s - loss: 2.5572e-05 - accuracy: 0.5675 - val_loss: 2.1116e-05 - val_accuracy: 0.5150 - 6s/epoch - 87ms/step\nEpoch 99/100\n72/72 - 6s - loss: 4.2710e-05 - accuracy: 0.5711 - val_loss: 1.4653e-05 - val_accuracy: 0.5275 - 6s/epoch - 86ms/step\nEpoch 100/100\n72/72 - 6s - loss: 2.1885e-04 - accuracy: 0.5669 - val_loss: 6.4304e-05 - val_accuracy: 0.5300 - 6s/epoch - 89ms/step\nEpoch 1/100\n72/72 - 6s - loss: 2.6737e-04 - accuracy: 0.5586 - val_loss: 0.0013 - val_accuracy: 0.5700 - 6s/epoch - 89ms/step\nEpoch 2/100\n72/72 - 6s - loss: 5.5339e-05 - accuracy: 0.5669 - val_loss: 9.0658e-04 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 3/100\n72/72 - 6s - loss: 1.1114e-04 - accuracy: 0.5619 - val_loss: 2.0122e-04 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 4/100\n72/72 - 6s - loss: 1.0491e-04 - accuracy: 0.5675 - val_loss: 6.6557e-04 - val_accuracy: 0.5775 - 6s/epoch - 86ms/step\nEpoch 5/100\n72/72 - 6s - loss: 3.4962e-05 - accuracy: 0.5753 - val_loss: 0.0013 - val_accuracy: 0.5775 - 6s/epoch - 87ms/step\nEpoch 6/100\n72/72 - 6s - loss: 6.2585e-05 - accuracy: 0.5692 - val_loss: 0.0016 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 7/100\n72/72 - 6s - loss: 2.7733e-04 - accuracy: 0.5597 - val_loss: 9.4243e-04 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 8/100\n72/72 - 6s - loss: 1.7117e-04 - accuracy: 0.5586 - val_loss: 0.0011 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 9/100\n72/72 - 6s - loss: 8.9579e-04 - accuracy: 0.5525 - val_loss: 4.7468e-04 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 10/100\n72/72 - 6s - loss: 9.1316e-05 - accuracy: 0.5550 - val_loss: 4.3108e-04 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 11/100\n72/72 - 6s - loss: 9.9662e-05 - accuracy: 0.5597 - val_loss: 9.3411e-04 - val_accuracy: 0.5500 - 6s/epoch - 88ms/step\nEpoch 12/100\n72/72 - 6s - loss: 2.0510e-04 - accuracy: 0.5658 - val_loss: 6.0194e-04 - val_accuracy: 0.5750 - 6s/epoch - 87ms/step\nEpoch 13/100\n72/72 - 6s - loss: 1.0107e-04 - accuracy: 0.5683 - val_loss: 2.2795e-05 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 14/100\n72/72 - 6s - loss: 3.3229e-04 - accuracy: 0.5569 - val_loss: 1.7035e-04 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 15/100\n72/72 - 6s - loss: 5.2526e-05 - accuracy: 0.5644 - val_loss: 9.9680e-05 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 16/100\n72/72 - 6s - loss: 2.8066e-05 - accuracy: 0.5619 - val_loss: 1.0170e-04 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 17/100\n72/72 - 6s - loss: 2.8471e-05 - accuracy: 0.5639 - val_loss: 1.7577e-04 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 18/100\n72/72 - 6s - loss: 1.2869e-04 - accuracy: 0.5592 - val_loss: 6.5728e-06 - val_accuracy: 0.5750 - 6s/epoch - 87ms/step\nEpoch 19/100\n72/72 - 6s - loss: 1.3134e-04 - accuracy: 0.5586 - val_loss: 7.4715e-06 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 20/100\n72/72 - 6s - loss: 4.3023e-05 - accuracy: 0.5586 - val_loss: 8.3104e-07 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 21/100\n72/72 - 6s - loss: 2.3449e-05 - accuracy: 0.5617 - val_loss: 3.5508e-07 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 22/100\n72/72 - 6s - loss: 2.4654e-05 - accuracy: 0.5572 - val_loss: 3.7086e-07 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 23/100\n72/72 - 6s - loss: 3.9810e-05 - accuracy: 0.5633 - val_loss: 9.0628e-07 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 24/100\n72/72 - 6s - loss: 5.7652e-05 - accuracy: 0.5619 - val_loss: 8.3331e-07 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 25/100\n72/72 - 6s - loss: 2.3633e-05 - accuracy: 0.5611 - val_loss: 3.8612e-07 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 26/100\n72/72 - 6s - loss: 1.6083e-05 - accuracy: 0.5558 - val_loss: 4.6354e-07 - val_accuracy: 0.5550 - 6s/epoch - 88ms/step\nEpoch 27/100\n72/72 - 6s - loss: 1.1121e-05 - accuracy: 0.5542 - val_loss: 2.7916e-07 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 28/100\n72/72 - 6s - loss: 1.6768e-05 - accuracy: 0.5617 - val_loss: 9.2664e-07 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 29/100\n72/72 - 6s - loss: 4.5753e-05 - accuracy: 0.5575 - val_loss: 3.1925e-07 - val_accuracy: 0.5525 - 6s/epoch - 85ms/step\nEpoch 30/100\n72/72 - 6s - loss: 1.3041e-05 - accuracy: 0.5558 - val_loss: 1.1470e-06 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 31/100\n72/72 - 6s - loss: 1.7499e-05 - accuracy: 0.5631 - val_loss: 4.3386e-06 - val_accuracy: 0.5600 - 6s/epoch - 88ms/step\nEpoch 32/100\n72/72 - 6s - loss: 1.7486e-05 - accuracy: 0.5558 - val_loss: 1.1513e-06 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 33/100\n72/72 - 6s - loss: 3.2076e-05 - accuracy: 0.5614 - val_loss: 2.0164e-05 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 34/100\n72/72 - 6s - loss: 1.6145e-05 - accuracy: 0.5564 - val_loss: 5.4560e-05 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 35/100\n72/72 - 6s - loss: 3.2359e-05 - accuracy: 0.5519 - val_loss: 1.5364e-05 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 36/100\n72/72 - 6s - loss: 2.3177e-05 - accuracy: 0.5564 - val_loss: 7.9253e-06 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 37/100\n72/72 - 6s - loss: 1.2347e-04 - accuracy: 0.5644 - val_loss: 1.8001e-06 - val_accuracy: 0.5875 - 6s/epoch - 87ms/step\nEpoch 38/100\n72/72 - 6s - loss: 1.4272e-04 - accuracy: 0.5675 - val_loss: 9.5691e-06 - val_accuracy: 0.5875 - 6s/epoch - 86ms/step\nEpoch 39/100\n72/72 - 6s - loss: 1.1158e-04 - accuracy: 0.5658 - val_loss: 8.2678e-06 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 40/100\n72/72 - 6s - loss: 3.2006e-04 - accuracy: 0.5667 - val_loss: 3.7135e-05 - val_accuracy: 0.5325 - 6s/epoch - 86ms/step\nEpoch 41/100\n72/72 - 6s - loss: 2.3605e-04 - accuracy: 0.5658 - val_loss: 6.2622e-05 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 42/100\n72/72 - 6s - loss: 1.0402e-04 - accuracy: 0.5653 - val_loss: 4.6961e-05 - val_accuracy: 0.5525 - 6s/epoch - 88ms/step\nEpoch 43/100\n72/72 - 6s - loss: 1.4779e-04 - accuracy: 0.5675 - val_loss: 1.0373e-05 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 44/100\n72/72 - 6s - loss: 7.9906e-05 - accuracy: 0.5697 - val_loss: 1.3831e-05 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 45/100\n72/72 - 6s - loss: 2.0009e-05 - accuracy: 0.5681 - val_loss: 1.1298e-04 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 46/100\n72/72 - 6s - loss: 9.6058e-05 - accuracy: 0.5617 - val_loss: 5.4320e-04 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 47/100\n72/72 - 6s - loss: 5.6260e-05 - accuracy: 0.5628 - val_loss: 5.7940e-04 - val_accuracy: 0.5650 - 6s/epoch - 88ms/step\nEpoch 48/100\n72/72 - 6s - loss: 1.5285e-05 - accuracy: 0.5650 - val_loss: 4.7142e-04 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 49/100\n72/72 - 6s - loss: 6.7598e-05 - accuracy: 0.5642 - val_loss: 1.9714e-04 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 50/100\n72/72 - 6s - loss: 1.4733e-05 - accuracy: 0.5600 - val_loss: 1.1652e-04 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 51/100\n72/72 - 6s - loss: 3.7743e-05 - accuracy: 0.5631 - val_loss: 2.9685e-04 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 52/100\n72/72 - 6s - loss: 9.2204e-06 - accuracy: 0.5603 - val_loss: 1.9579e-04 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 53/100\n72/72 - 6s - loss: 1.0057e-05 - accuracy: 0.5625 - val_loss: 3.8628e-04 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 54/100\n72/72 - 6s - loss: 2.5725e-05 - accuracy: 0.5622 - val_loss: 2.8221e-06 - val_accuracy: 0.5400 - 6s/epoch - 86ms/step\nEpoch 55/100\n72/72 - 6s - loss: 4.3721e-05 - accuracy: 0.5600 - val_loss: 7.2901e-06 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 56/100\n72/72 - 6s - loss: 2.1746e-05 - accuracy: 0.5583 - val_loss: 6.2286e-05 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 57/100\n72/72 - 6s - loss: 7.5481e-05 - accuracy: 0.5581 - val_loss: 1.7864e-04 - val_accuracy: 0.5500 - 6s/epoch - 88ms/step\nEpoch 58/100\n72/72 - 6s - loss: 1.4160e-04 - accuracy: 0.5606 - val_loss: 1.3242e-04 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 59/100\n72/72 - 6s - loss: 1.3562e-04 - accuracy: 0.5575 - val_loss: 1.3236e-05 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 60/100\n72/72 - 6s - loss: 6.3323e-05 - accuracy: 0.5533 - val_loss: 6.4811e-05 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 61/100\n72/72 - 6s - loss: 1.3637e-05 - accuracy: 0.5489 - val_loss: 1.5807e-05 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 62/100\n72/72 - 6s - loss: 9.8740e-05 - accuracy: 0.5517 - val_loss: 5.9863e-05 - val_accuracy: 0.5400 - 6s/epoch - 88ms/step\nEpoch 63/100\n72/72 - 6s - loss: 2.7115e-05 - accuracy: 0.5525 - val_loss: 4.9250e-06 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 64/100\n72/72 - 6s - loss: 2.3527e-05 - accuracy: 0.5547 - val_loss: 4.2709e-05 - val_accuracy: 0.5400 - 6s/epoch - 87ms/step\nEpoch 65/100\n72/72 - 6s - loss: 1.2853e-05 - accuracy: 0.5525 - val_loss: 1.3745e-05 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 66/100\n72/72 - 6s - loss: 2.3210e-05 - accuracy: 0.5517 - val_loss: 9.1516e-06 - val_accuracy: 0.5400 - 6s/epoch - 86ms/step\nEpoch 67/100\n72/72 - 6s - loss: 1.6932e-05 - accuracy: 0.5508 - val_loss: 3.3922e-05 - val_accuracy: 0.5375 - 6s/epoch - 88ms/step\nEpoch 68/100\n72/72 - 6s - loss: 1.3053e-05 - accuracy: 0.5531 - val_loss: 1.4091e-04 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 69/100\n72/72 - 6s - loss: 2.8594e-05 - accuracy: 0.5533 - val_loss: 4.9700e-05 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 70/100\n72/72 - 6s - loss: 5.3671e-05 - accuracy: 0.5544 - val_loss: 1.4536e-05 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 71/100\n72/72 - 6s - loss: 1.7351e-05 - accuracy: 0.5542 - val_loss: 7.1610e-06 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 72/100\n72/72 - 6s - loss: 9.0000e-06 - accuracy: 0.5522 - val_loss: 3.7805e-06 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 73/100\n72/72 - 6s - loss: 1.0866e-05 - accuracy: 0.5544 - val_loss: 4.0669e-06 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 74/100\n72/72 - 6s - loss: 1.6160e-05 - accuracy: 0.5544 - val_loss: 9.0353e-06 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 75/100\n72/72 - 6s - loss: 6.1570e-06 - accuracy: 0.5514 - val_loss: 6.0657e-06 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\nEpoch 76/100\n72/72 - 6s - loss: 1.4102e-05 - accuracy: 0.5525 - val_loss: 2.7178e-05 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 77/100\n72/72 - 6s - loss: 8.6870e-06 - accuracy: 0.5581 - val_loss: 4.4269e-05 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 78/100\n72/72 - 6s - loss: 9.5463e-06 - accuracy: 0.5600 - val_loss: 5.3048e-05 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 79/100\n72/72 - 6s - loss: 1.2223e-05 - accuracy: 0.5564 - val_loss: 3.6704e-05 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 80/100\n72/72 - 6s - loss: 1.1769e-05 - accuracy: 0.5536 - val_loss: 6.7164e-05 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 81/100\n72/72 - 6s - loss: 9.4105e-06 - accuracy: 0.5553 - val_loss: 4.4379e-05 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 82/100\n72/72 - 6s - loss: 2.1783e-05 - accuracy: 0.5550 - val_loss: 3.5528e-05 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 83/100\n72/72 - 6s - loss: 1.2256e-05 - accuracy: 0.5511 - val_loss: 2.8204e-05 - val_accuracy: 0.5375 - 6s/epoch - 86ms/step\nEpoch 84/100\n72/72 - 6s - loss: 1.0044e-05 - accuracy: 0.5531 - val_loss: 4.6805e-05 - val_accuracy: 0.5400 - 6s/epoch - 86ms/step\nEpoch 85/100\n72/72 - 6s - loss: 6.6498e-06 - accuracy: 0.5531 - val_loss: 4.6199e-05 - val_accuracy: 0.5425 - 6s/epoch - 87ms/step\nEpoch 86/100\n72/72 - 6s - loss: 1.3629e-05 - accuracy: 0.5547 - val_loss: 1.9496e-05 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 87/100\n72/72 - 6s - loss: 3.8558e-05 - accuracy: 0.5631 - val_loss: 7.1882e-05 - val_accuracy: 0.5700 - 6s/epoch - 88ms/step\nEpoch 88/100\n72/72 - 6s - loss: 8.2632e-06 - accuracy: 0.5606 - val_loss: 4.6011e-05 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 89/100\n72/72 - 6s - loss: 7.4864e-06 - accuracy: 0.5608 - val_loss: 4.3373e-05 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 90/100\n72/72 - 6s - loss: 7.8384e-06 - accuracy: 0.5617 - val_loss: 8.9949e-05 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 91/100\n72/72 - 6s - loss: 8.4706e-06 - accuracy: 0.5611 - val_loss: 7.4048e-05 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 92/100\n72/72 - 6s - loss: 6.3482e-05 - accuracy: 0.5572 - val_loss: 8.7833e-05 - val_accuracy: 0.5375 - 6s/epoch - 88ms/step\nEpoch 93/100\n72/72 - 6s - loss: 5.1816e-05 - accuracy: 0.5614 - val_loss: 9.9737e-05 - val_accuracy: 0.5850 - 6s/epoch - 86ms/step\nEpoch 94/100\n72/72 - 6s - loss: 1.8503e-05 - accuracy: 0.5703 - val_loss: 7.3625e-05 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 95/100\n72/72 - 6s - loss: 3.0332e-05 - accuracy: 0.5667 - val_loss: 8.9204e-05 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 96/100\n72/72 - 6s - loss: 2.2335e-05 - accuracy: 0.5719 - val_loss: 1.6242e-05 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 97/100\n72/72 - 6s - loss: 1.5065e-05 - accuracy: 0.5722 - val_loss: 2.5553e-05 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 98/100\n72/72 - 6s - loss: 3.7147e-05 - accuracy: 0.5775 - val_loss: 9.0430e-06 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 99/100\n72/72 - 6s - loss: 1.4278e-04 - accuracy: 0.5803 - val_loss: 2.7508e-06 - val_accuracy: 0.5750 - 6s/epoch - 86ms/step\nEpoch 100/100\n72/72 - 6s - loss: 8.3233e-05 - accuracy: 0.5806 - val_loss: 5.0110e-07 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 1/100\n72/72 - 6s - loss: 1.0977e-05 - accuracy: 0.5703 - val_loss: 2.5295e-08 - val_accuracy: 0.5625 - 6s/epoch - 89ms/step\nEpoch 2/100\n72/72 - 6s - loss: 2.7946e-05 - accuracy: 0.5736 - val_loss: 1.7940e-08 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 3/100\n72/72 - 6s - loss: 3.1942e-05 - accuracy: 0.5728 - val_loss: 1.2668e-08 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 4/100\n72/72 - 6s - loss: 2.7011e-05 - accuracy: 0.5711 - val_loss: 1.3505e-08 - val_accuracy: 0.5525 - 6s/epoch - 86ms/step\nEpoch 5/100\n72/72 - 6s - loss: 3.8566e-05 - accuracy: 0.5644 - val_loss: 1.9055e-08 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 6/100\n72/72 - 6s - loss: 4.7466e-05 - accuracy: 0.5706 - val_loss: 3.0213e-08 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 7/100\n72/72 - 6s - loss: 1.5723e-05 - accuracy: 0.5697 - val_loss: 2.2622e-08 - val_accuracy: 0.5625 - 6s/epoch - 88ms/step\nEpoch 8/100\n72/72 - 6s - loss: 1.5178e-05 - accuracy: 0.5606 - val_loss: 1.4539e-08 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 9/100\n72/72 - 6s - loss: 8.2167e-06 - accuracy: 0.5606 - val_loss: 9.6359e-09 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 10/100\n72/72 - 6s - loss: 1.6738e-05 - accuracy: 0.5664 - val_loss: 7.5104e-09 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 11/100\n72/72 - 6s - loss: 3.3655e-05 - accuracy: 0.5731 - val_loss: 1.2449e-08 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 12/100\n72/72 - 6s - loss: 5.5470e-06 - accuracy: 0.5625 - val_loss: 1.0224e-08 - val_accuracy: 0.5550 - 6s/epoch - 88ms/step\nEpoch 13/100\n72/72 - 6s - loss: 4.3055e-05 - accuracy: 0.5572 - val_loss: 1.8745e-08 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 14/100\n72/72 - 6s - loss: 3.0422e-05 - accuracy: 0.5575 - val_loss: 9.7099e-09 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 15/100\n72/72 - 6s - loss: 2.1133e-05 - accuracy: 0.5625 - val_loss: 9.5261e-09 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 16/100\n72/72 - 6s - loss: 7.7872e-05 - accuracy: 0.5586 - val_loss: 2.1610e-07 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 17/100\n72/72 - 6s - loss: 2.1673e-05 - accuracy: 0.5717 - val_loss: 2.8645e-08 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 18/100\n72/72 - 6s - loss: 1.0408e-05 - accuracy: 0.5656 - val_loss: 2.4256e-08 - val_accuracy: 0.5675 - 6s/epoch - 88ms/step\nEpoch 19/100\n72/72 - 6s - loss: 8.4256e-06 - accuracy: 0.5667 - val_loss: 1.9511e-08 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 20/100\n72/72 - 6s - loss: 4.1222e-06 - accuracy: 0.5675 - val_loss: 1.9423e-08 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 21/100\n72/72 - 6s - loss: 1.9726e-05 - accuracy: 0.5636 - val_loss: 3.6641e-08 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 22/100\n72/72 - 6s - loss: 4.9141e-06 - accuracy: 0.5633 - val_loss: 2.5408e-08 - val_accuracy: 0.5500 - 6s/epoch - 88ms/step\nEpoch 23/100\n72/72 - 6s - loss: 1.8303e-05 - accuracy: 0.5689 - val_loss: 3.3604e-08 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 24/100\n72/72 - 6s - loss: 1.6116e-04 - accuracy: 0.5644 - val_loss: 6.8016e-08 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 25/100\n72/72 - 6s - loss: 1.9677e-05 - accuracy: 0.5597 - val_loss: 2.4702e-08 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 26/100\n72/72 - 6s - loss: 9.2232e-06 - accuracy: 0.5619 - val_loss: 1.4560e-08 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 27/100\n72/72 - 6s - loss: 3.5617e-05 - accuracy: 0.5617 - val_loss: 3.3694e-08 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 28/100\n72/72 - 6s - loss: 1.7034e-05 - accuracy: 0.5647 - val_loss: 2.0051e-08 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 29/100\n72/72 - 6s - loss: 2.2719e-05 - accuracy: 0.5619 - val_loss: 2.1291e-08 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 30/100\n72/72 - 6s - loss: 4.0947e-05 - accuracy: 0.5731 - val_loss: 9.1163e-08 - val_accuracy: 0.5950 - 6s/epoch - 87ms/step\nEpoch 31/100\n72/72 - 6s - loss: 5.7271e-05 - accuracy: 0.5772 - val_loss: 1.8472e-08 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 32/100\n72/72 - 6s - loss: 2.3858e-05 - accuracy: 0.5667 - val_loss: 2.8060e-08 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 33/100\n72/72 - 6s - loss: 1.1116e-04 - accuracy: 0.5761 - val_loss: 5.8069e-08 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 34/100\n72/72 - 6s - loss: 2.1266e-04 - accuracy: 0.5647 - val_loss: 5.2920e-05 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 35/100\n72/72 - 6s - loss: 9.2770e-04 - accuracy: 0.5558 - val_loss: 6.1584e-04 - val_accuracy: 0.5250 - 6s/epoch - 86ms/step\nEpoch 36/100\n72/72 - 6s - loss: 3.9996e-04 - accuracy: 0.5550 - val_loss: 0.0046 - val_accuracy: 0.5200 - 6s/epoch - 87ms/step\nEpoch 37/100\n72/72 - 6s - loss: 5.3313e-05 - accuracy: 0.5608 - val_loss: 0.0011 - val_accuracy: 0.5300 - 6s/epoch - 86ms/step\nEpoch 38/100\n72/72 - 6s - loss: 1.2840e-04 - accuracy: 0.5600 - val_loss: 7.0319e-04 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 39/100\n72/72 - 6s - loss: 3.6938e-05 - accuracy: 0.5678 - val_loss: 1.7297e-04 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 40/100\n72/72 - 6s - loss: 6.5423e-05 - accuracy: 0.5675 - val_loss: 3.1947e-05 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 41/100\n72/72 - 6s - loss: 3.4858e-05 - accuracy: 0.5650 - val_loss: 2.7120e-05 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 42/100\n72/72 - 6s - loss: 1.6205e-05 - accuracy: 0.5664 - val_loss: 1.8502e-05 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 43/100\n72/72 - 6s - loss: 8.3134e-05 - accuracy: 0.5594 - val_loss: 7.4867e-05 - val_accuracy: 0.5450 - 6s/epoch - 88ms/step\nEpoch 44/100\n72/72 - 6s - loss: 1.3104e-04 - accuracy: 0.5567 - val_loss: 7.3131e-05 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 45/100\n72/72 - 6s - loss: 6.6663e-05 - accuracy: 0.5558 - val_loss: 3.9804e-06 - val_accuracy: 0.5575 - 6s/epoch - 87ms/step\nEpoch 46/100\n72/72 - 6s - loss: 2.7169e-05 - accuracy: 0.5578 - val_loss: 5.8885e-06 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 47/100\n72/72 - 6s - loss: 1.3800e-04 - accuracy: 0.5594 - val_loss: 1.7594e-06 - val_accuracy: 0.5575 - 6s/epoch - 86ms/step\nEpoch 48/100\n72/72 - 6s - loss: 7.8555e-05 - accuracy: 0.5600 - val_loss: 9.2371e-06 - val_accuracy: 0.5500 - 6s/epoch - 89ms/step\nEpoch 49/100\n72/72 - 6s - loss: 4.4379e-05 - accuracy: 0.5558 - val_loss: 1.2610e-06 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 50/100\n72/72 - 6s - loss: 3.2889e-05 - accuracy: 0.5622 - val_loss: 7.2165e-07 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 51/100\n72/72 - 6s - loss: 1.4729e-05 - accuracy: 0.5731 - val_loss: 4.4563e-06 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 52/100\n72/72 - 6s - loss: 9.0787e-06 - accuracy: 0.5619 - val_loss: 4.9801e-06 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 53/100\n72/72 - 6s - loss: 1.1108e-04 - accuracy: 0.5653 - val_loss: 1.3516e-06 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 54/100\n72/72 - 6s - loss: 5.8191e-05 - accuracy: 0.5636 - val_loss: 9.1775e-07 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 55/100\n72/72 - 6s - loss: 1.0299e-04 - accuracy: 0.5761 - val_loss: 4.8712e-07 - val_accuracy: 0.5850 - 6s/epoch - 87ms/step\nEpoch 56/100\n72/72 - 6s - loss: 4.2052e-05 - accuracy: 0.5742 - val_loss: 1.1914e-06 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 57/100\n72/72 - 6s - loss: 3.2328e-05 - accuracy: 0.5736 - val_loss: 1.0207e-06 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 58/100\n72/72 - 6s - loss: 1.2170e-05 - accuracy: 0.5678 - val_loss: 1.4224e-06 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 59/100\n72/72 - 6s - loss: 4.2640e-05 - accuracy: 0.5642 - val_loss: 6.4527e-07 - val_accuracy: 0.5650 - 6s/epoch - 86ms/step\nEpoch 60/100\n72/72 - 6s - loss: 9.0377e-05 - accuracy: 0.5692 - val_loss: 7.0818e-07 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 61/100\n72/72 - 6s - loss: 3.8895e-05 - accuracy: 0.5625 - val_loss: 4.1281e-07 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 62/100\n72/72 - 6s - loss: 7.2289e-05 - accuracy: 0.5647 - val_loss: 1.8286e-06 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 63/100\n72/72 - 6s - loss: 1.4935e-05 - accuracy: 0.5567 - val_loss: 1.7377e-06 - val_accuracy: 0.5650 - 6s/epoch - 88ms/step\nEpoch 64/100\n72/72 - 6s - loss: 2.0552e-05 - accuracy: 0.5611 - val_loss: 1.2887e-06 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 65/100\n72/72 - 6s - loss: 1.7014e-05 - accuracy: 0.5611 - val_loss: 3.2537e-06 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 66/100\n72/72 - 6s - loss: 4.8193e-05 - accuracy: 0.5622 - val_loss: 7.2319e-07 - val_accuracy: 0.5675 - 6s/epoch - 87ms/step\nEpoch 67/100\n72/72 - 6s - loss: 1.1220e-05 - accuracy: 0.5569 - val_loss: 6.5222e-07 - val_accuracy: 0.5650 - 6s/epoch - 87ms/step\nEpoch 68/100\n72/72 - 6s - loss: 7.5407e-06 - accuracy: 0.5614 - val_loss: 5.7593e-07 - val_accuracy: 0.5650 - 6s/epoch - 88ms/step\nEpoch 69/100\n72/72 - 6s - loss: 7.2256e-05 - accuracy: 0.5628 - val_loss: 2.8205e-07 - val_accuracy: 0.5675 - 6s/epoch - 86ms/step\nEpoch 70/100\n72/72 - 6s - loss: 9.9119e-05 - accuracy: 0.5661 - val_loss: 1.0742e-07 - val_accuracy: 0.5750 - 6s/epoch - 86ms/step\nEpoch 71/100\n72/72 - 6s - loss: 1.0419e-04 - accuracy: 0.5592 - val_loss: 1.5062e-06 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 72/100\n72/72 - 6s - loss: 1.2043e-05 - accuracy: 0.5542 - val_loss: 2.4383e-07 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 73/100\n72/72 - 6s - loss: 7.0892e-05 - accuracy: 0.5514 - val_loss: 1.5245e-07 - val_accuracy: 0.5475 - 6s/epoch - 87ms/step\nEpoch 74/100\n72/72 - 6s - loss: 3.4078e-05 - accuracy: 0.5575 - val_loss: 2.8017e-07 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 75/100\n72/72 - 6s - loss: 1.4255e-05 - accuracy: 0.5578 - val_loss: 2.8499e-07 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 76/100\n72/72 - 6s - loss: 9.6640e-06 - accuracy: 0.5597 - val_loss: 2.0403e-07 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 77/100\n72/72 - 6s - loss: 1.3457e-05 - accuracy: 0.5644 - val_loss: 1.1011e-07 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 78/100\n72/72 - 6s - loss: 2.1387e-05 - accuracy: 0.5647 - val_loss: 6.3330e-07 - val_accuracy: 0.5700 - 6s/epoch - 88ms/step\nEpoch 79/100\n72/72 - 6s - loss: 1.4365e-05 - accuracy: 0.5678 - val_loss: 3.0181e-07 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 80/100\n72/72 - 6s - loss: 1.3487e-05 - accuracy: 0.5675 - val_loss: 1.9631e-07 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 81/100\n72/72 - 6s - loss: 1.1466e-05 - accuracy: 0.5631 - val_loss: 2.0053e-07 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 82/100\n72/72 - 6s - loss: 3.6263e-05 - accuracy: 0.5678 - val_loss: 2.8406e-07 - val_accuracy: 0.5700 - 6s/epoch - 86ms/step\nEpoch 83/100\n72/72 - 6s - loss: 1.9324e-04 - accuracy: 0.5642 - val_loss: 7.6043e-08 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 84/100\n72/72 - 6s - loss: 8.7369e-05 - accuracy: 0.5606 - val_loss: 1.5786e-07 - val_accuracy: 0.5625 - 6s/epoch - 86ms/step\nEpoch 85/100\n72/72 - 6s - loss: 2.3568e-05 - accuracy: 0.5697 - val_loss: 5.2857e-08 - val_accuracy: 0.5600 - 6s/epoch - 86ms/step\nEpoch 86/100\n72/72 - 6s - loss: 7.2193e-05 - accuracy: 0.5589 - val_loss: 2.5892e-07 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 87/100\n72/72 - 6s - loss: 2.7617e-05 - accuracy: 0.5575 - val_loss: 5.3265e-08 - val_accuracy: 0.5550 - 6s/epoch - 86ms/step\nEpoch 88/100\n72/72 - 6s - loss: 3.2989e-05 - accuracy: 0.5572 - val_loss: 1.1713e-07 - val_accuracy: 0.5625 - 6s/epoch - 87ms/step\nEpoch 89/100\n72/72 - 6s - loss: 1.0220e-04 - accuracy: 0.5611 - val_loss: 4.2618e-07 - val_accuracy: 0.5525 - 6s/epoch - 87ms/step\nEpoch 90/100\n72/72 - 6s - loss: 9.2580e-05 - accuracy: 0.5653 - val_loss: 8.5368e-08 - val_accuracy: 0.5500 - 6s/epoch - 86ms/step\nEpoch 91/100\n72/72 - 6s - loss: 1.5196e-05 - accuracy: 0.5628 - val_loss: 1.3655e-07 - val_accuracy: 0.5475 - 6s/epoch - 86ms/step\nEpoch 92/100\n72/72 - 6s - loss: 6.3110e-05 - accuracy: 0.5578 - val_loss: 2.4066e-07 - val_accuracy: 0.5425 - 6s/epoch - 86ms/step\nEpoch 93/100\n72/72 - 6s - loss: 5.0323e-04 - accuracy: 0.5678 - val_loss: 4.9144e-06 - val_accuracy: 0.5750 - 6s/epoch - 87ms/step\nEpoch 94/100\n72/72 - 6s - loss: 5.9505e-05 - accuracy: 0.5758 - val_loss: 1.3513e-06 - val_accuracy: 0.5650 - 6s/epoch - 88ms/step\nEpoch 95/100\n72/72 - 6s - loss: 1.7843e-04 - accuracy: 0.5722 - val_loss: 7.5762e-05 - val_accuracy: 0.5550 - 6s/epoch - 87ms/step\nEpoch 96/100\n72/72 - 6s - loss: 1.3592e-04 - accuracy: 0.5731 - val_loss: 1.5040e-06 - val_accuracy: 0.5450 - 6s/epoch - 87ms/step\nEpoch 97/100\n72/72 - 6s - loss: 1.0358e-04 - accuracy: 0.5689 - val_loss: 2.2391e-06 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 98/100\n72/72 - 6s - loss: 1.6200e-05 - accuracy: 0.5617 - val_loss: 1.7579e-06 - val_accuracy: 0.5500 - 6s/epoch - 87ms/step\nEpoch 99/100\n72/72 - 6s - loss: 1.0219e-04 - accuracy: 0.5583 - val_loss: 4.0565e-04 - val_accuracy: 0.5600 - 6s/epoch - 87ms/step\nEpoch 100/100\n72/72 - 6s - loss: 1.3994e-04 - accuracy: 0.5567 - val_loss: 7.7483e-04 - val_accuracy: 0.5450 - 6s/epoch - 86ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred = model.predict(X_val)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:24:31.476150Z","iopub.execute_input":"2023-09-02T14:24:31.477247Z","iopub.status.idle":"2023-09-02T14:24:35.251058Z","shell.execute_reply.started":"2023-09-02T14:24:31.477209Z","shell.execute_reply":"2023-09-02T14:24:35.249920Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"13/13 [==============================] - 4s 84ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_val = y_pred>0.5\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:25:20.100323Z","iopub.execute_input":"2023-09-02T14:25:20.101130Z","iopub.status.idle":"2023-09-02T14:25:20.105860Z","shell.execute_reply.started":"2023-09-02T14:25:20.101093Z","shell.execute_reply":"2023-09-02T14:25:20.104732Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"y_val","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:26:17.924643Z","iopub.execute_input":"2023-09-02T14:26:17.925094Z","iopub.status.idle":"2023-09-02T14:26:17.935017Z","shell.execute_reply.started":"2023-09-02T14:26:17.925060Z","shell.execute_reply":"2023-09-02T14:26:17.933538Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"array([[1, 0, 1, ..., 0, 1, 1],\n       [0, 0, 0, ..., 0, 0, 0],\n       [1, 0, 1, ..., 1, 1, 1],\n       ...,\n       [1, 1, 1, ..., 1, 1, 1],\n       [1, 1, 1, ..., 1, 1, 0],\n       [0, 0, 1, ..., 1, 1, 1]])"},"metadata":{}}]},{"cell_type":"code","source":"true_labels = y_val.copy()\npredicted_labels = y_pred_val.copy()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:29:31.557924Z","iopub.execute_input":"2023-09-02T14:29:31.558471Z","iopub.status.idle":"2023-09-02T14:29:31.565159Z","shell.execute_reply.started":"2023-09-02T14:29:31.558430Z","shell.execute_reply":"2023-09-02T14:29:31.564023Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nmacro_f1 = f1_score(true_labels, predicted_labels, average='macro')\n\n# Calculate micro-average F1 score\nmicro_f1 = f1_score(true_labels, predicted_labels, average='micro')\nprint(\"macro_f1 \", macro_f1)\nprint(\"micro_f1 \", micro_f1)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:29:35.037573Z","iopub.execute_input":"2023-09-02T14:29:35.037946Z","iopub.status.idle":"2023-09-02T14:29:35.061578Z","shell.execute_reply.started":"2023-09-02T14:29:35.037916Z","shell.execute_reply":"2023-09-02T14:29:35.060311Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"macro_f1  0.9997799779977998\nmicro_f1  0.9997778271495222\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:29:51.727221Z","iopub.execute_input":"2023-09-02T14:29:51.728038Z","iopub.status.idle":"2023-09-02T14:29:51.732743Z","shell.execute_reply.started":"2023-09-02T14:29:51.727986Z","shell.execute_reply":"2023-09-02T14:29:51.731662Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:29:51.977566Z","iopub.execute_input":"2023-09-02T14:29:51.980557Z","iopub.status.idle":"2023-09-02T14:29:53.026714Z","shell.execute_reply.started":"2023-09-02T14:29:51.980517Z","shell.execute_reply":"2023-09-02T14:29:53.025553Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nfrom PIL import Image\n\ndef create_matrix_collage(image_paths, rows, cols, output_size):\n    collage = Image.new('RGB', output_size)\n    width_per_image = output_size[0] // cols\n    height_per_image = output_size[1] // rows\n\n    for i in range(rows):\n        for j in range(cols):\n            img_path = image_paths[i * cols + j]\n            img = Image.open(img_path)\n            img = img.resize((width_per_image, height_per_image), Image.ANTIALIAS)\n            collage.paste(img, (j * width_per_image, i * height_per_image))\n\n    return collage\n\n\n\ndef image_generator(num = 205):\n    base_path = \"/kaggle/input/vegetable-image-dataset/Vegetable Images/test\"\n    veget = os.listdir(base_path)\n    veget.sort()\n    labels = []\n    for i in range(1, num+1):\n        image_paths = []  # Replace with your image paths\n        rows = 4  # Number of rows in the collage\n        cols = 4  # Number of columns in the collage\n        output_size = (128, 128)  # Size of the final collage image (rows * cols)\n        temp = [0]*15\n        for j in range(1, 17):\n            num = np.random.randint(0, 15)\n            veg_name = veget[num]\n            veg_path = os.path.join(base_path, veg_name)\n            img_num = np.random.randint(0, 200)\n            lst = os.listdir(veg_path)\n            veg_img_path = os.path.join(veg_path, lst[img_num])\n            image_paths.append(veg_img_path)\n            temp[num] = 1\n        \n        collage = create_matrix_collage(image_paths, rows, cols, output_size)\n        collage.save(f\"test/img_{i}.jpg\")\n        labels.append(temp)\n    return veget, labels\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:35:52.896801Z","iopub.execute_input":"2023-09-02T14:35:52.897956Z","iopub.status.idle":"2023-09-02T14:35:52.912261Z","shell.execute_reply.started":"2023-09-02T14:35:52.897919Z","shell.execute_reply":"2023-09-02T14:35:52.911091Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"veget, labels = image_generator(205)\nlabels_df = pd.DataFrame(labels, columns = veget)\nnewsize = (128, 128)\nbase_path = \"/kaggle/input/vegetable-image-dataset/Vegetable Images/test\"\nnew_path = \"/kaggle/working/test\"\nimg_num = 206\nadd_num = 3\nlabels = []\nfor id, name in enumerate(veget):\n    temp = [0]*15\n    temp[id] = 1\n    veg_name_path = os.path.join(base_path, name)\n    lst = os.listdir(veg_name_path)\n    for i in range(add_num):\n        num = np.random.randint(0, len(lst))\n        veg_img_path = os.path.join(veg_name_path, lst[num])\n        img = Image.open(veg_img_path)\n        img = img.resize(newsize)\n        img_name = f\"img_{img_num}\" + \".jpg\"\n        new_train_path = os.path.join(new_path, img_name)\n        img.save(new_train_path)\n        labels.append(temp)\n        img_num += 1\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:36:27.023681Z","iopub.execute_input":"2023-09-02T14:36:27.024158Z","iopub.status.idle":"2023-09-02T14:36:52.503445Z","shell.execute_reply.started":"2023-09-02T14:36:27.024122Z","shell.execute_reply":"2023-09-02T14:36:52.502341Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# !zip -r file.zip /kaggle/working\ntemp_df = pd.DataFrame(labels, columns = veget)\nlabels_df = pd.concat([labels_df, temp_df])\nlabels_df.reset_index(drop = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:38:38.315242Z","iopub.execute_input":"2023-09-02T14:38:38.315657Z","iopub.status.idle":"2023-09-02T14:38:38.325432Z","shell.execute_reply.started":"2023-09-02T14:38:38.315625Z","shell.execute_reply":"2023-09-02T14:38:38.324059Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"len(labels_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:38:43.538219Z","iopub.execute_input":"2023-09-02T14:38:43.538619Z","iopub.status.idle":"2023-09-02T14:38:43.547507Z","shell.execute_reply.started":"2023-09-02T14:38:43.538587Z","shell.execute_reply":"2023-09-02T14:38:43.546331Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"250"},"metadata":{}}]},{"cell_type":"code","source":"X_test = []; y_test = []\nfor img in os.listdir(\"/kaggle/working/test\"):\n    img_path = \"/kaggle/working/test\" + \"/\" + img\n    label = int(img.split(\"_\")[1].split(\".\")[0])-1\n    label = list(labels_df.iloc[label, :].values)\n    img = Image.open(img_path)\n    arr = np.asarray(img)\n    arr = data_augmentation(arr)\n    X_test.append(arr)\n    y_test.append(label)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:40:02.684917Z","iopub.execute_input":"2023-09-02T14:40:02.685364Z","iopub.status.idle":"2023-09-02T14:40:03.199118Z","shell.execute_reply.started":"2023-09-02T14:40:02.685331Z","shell.execute_reply":"2023-09-02T14:40:03.197932Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"X_test = np.array(X_test)\ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:40:24.428060Z","iopub.execute_input":"2023-09-02T14:40:24.429001Z","iopub.status.idle":"2023-09-02T14:40:24.480611Z","shell.execute_reply.started":"2023-09-02T14:40:24.428946Z","shell.execute_reply":"2023-09-02T14:40:24.479450Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"y_pred_test = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:42:17.042617Z","iopub.execute_input":"2023-09-02T14:42:17.043083Z","iopub.status.idle":"2023-09-02T14:42:18.423958Z","shell.execute_reply.started":"2023-09-02T14:42:17.043048Z","shell.execute_reply":"2023-09-02T14:42:18.422780Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"8/8 [==============================] - 1s 133ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"true_labels = y_test.copy()\npredicted_labels = y_pred_test>0.5","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:43:41.376882Z","iopub.execute_input":"2023-09-02T14:43:41.377645Z","iopub.status.idle":"2023-09-02T14:43:41.382578Z","shell.execute_reply.started":"2023-09-02T14:43:41.377613Z","shell.execute_reply":"2023-09-02T14:43:41.381293Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nmacro_f1 = f1_score(true_labels, predicted_labels, average='macro')\n\n# Calculate micro-average F1 score\nmicro_f1 = f1_score(true_labels, predicted_labels, average='micro')\nprint(\"macro_f1 \", macro_f1)\nprint(\"micro_f1 \", micro_f1)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T14:43:43.914644Z","iopub.execute_input":"2023-09-02T14:43:43.915852Z","iopub.status.idle":"2023-09-02T14:43:43.933004Z","shell.execute_reply.started":"2023-09-02T14:43:43.915812Z","shell.execute_reply":"2023-09-02T14:43:43.931632Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"macro_f1  0.8100320575789599\nmicro_f1  0.811175785797439\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install langchain","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}